{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Лабораторная работа №3 (Проведение исследований с решающим деревом)"
      ],
      "metadata": {
        "id": "z-cikdbGLyTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Классификация"
      ],
      "metadata": {
        "id": "YDqVsqmMiZ3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Создание бейзлайна и оценка качества"
      ],
      "metadata": {
        "id": "_0UVcEA2Fhkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Обучение модели sklearn**"
      ],
      "metadata": {
        "id": "55dr2bTYFqE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Загружаем данные\n",
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Преобразуем текстовые категории в числовые значения\n",
        "for col in ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Заполняем пропуски медианными значениями\n",
        "df = df.fillna(df.median())\n",
        "\n",
        "# Формируем матрицу признаков и целевой вектор\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "# Делим выборку на обучающую и тестовую (80/20)\n",
        "# Стратификация нужна, чтобы сохранить баланс классов\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Масштабируем признаки\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Инициализируем и обучаем дерево решений с параметрами по умолчанию\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Получаем предсказания классов и вероятностей\n",
        "y_pred = dt.predict(X_test)\n",
        "y_pred_proba = dt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Метрики\n",
        "print(\"Решающее дерево Бейзлайн\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNxt3OHZFw8s",
        "outputId": "81c6d37d-32e8-440c-da3c-c347f22f5d75"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Решающее дерево Бейзлайн\n",
            "Accuracy: 0.8920\n",
            "Precision: 0.7462\n",
            "Recall: 0.7651\n",
            "F1-Score: 0.7556\n",
            "ROC-AUC: 0.8462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Оценка качества модели**\n",
        "\n",
        "- Accuracy: 0.8920\n",
        "- Precision: 0.7462\n",
        "- Recall: 0.7651\n",
        "- F1-Score: 0.7556\n",
        "- ROC-AUC: 0.8462\n",
        "\n",
        "Модель, можно сказать, из коробки показала весьма достойные результаты, но возможно есть риск, что произошло переобучение, поэтому в следующем пункте попробую исправить это настройкой глубины."
      ],
      "metadata": {
        "id": "Xqb81TZ3Iz09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Улучшение бейзлайна"
      ],
      "metadata": {
        "id": "4oWLctvDJgmM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Формулировка гипотез**\n",
        "\n",
        "**Гипотеза 1: Препроцессинг**\n",
        "\n",
        "Данные содержат явные выбросы (например, стаж 123 года). Удаление аномалий по возрасту и стажу, ну и замена Label Encoding на One-hot encoding для категорий должны помочь дереву строить более логичные правила ветвления.\n",
        "\n",
        "**Гипотеза 2: Подбор гиперпараметров**\n",
        "\n",
        "Деревья решений склонны к переобучению, они могут строить слишком глубокие и сложные структуры, запоминая шумы. А если мы ограниченим максимальную глубину и минимальное количество объектов в листе через кросс-валидацию, это поможет упростить модель, убрать переобучение и, возможно, повысить Precision.\n",
        "\n",
        "**Гипотеза 3: Отбор признаков (Feature Importance)**\n",
        "\n",
        "Дерево умеет оценивать важность признаков, поэтому если после обучения посмотреть на feature_importances и удалить признаки с нулевой или ничтожной важностью, можно убрать шум и улучшить качество.\n",
        "\n",
        "**Гипотеза 4: Балансировка классов**\n",
        "\n",
        "Попробуем применить class_weight='balanced' прямо внутри модели вместо внешнего SMOTE. Это может еще сильнее поднять Recall."
      ],
      "metadata": {
        "id": "Z07kqabuJnCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Проверка гипотез**"
      ],
      "metadata": {
        "id": "yFRIhg8-Jzbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Удаляем выбросы\n",
        "print(\"До удаления выбросов:\", len(df))\n",
        "df = df[(df['person_age'] < 100) & (df['person_emp_length'] < 100)]\n",
        "print(\"После удаления выбросов:\", len(df))\n",
        "\n",
        "# Заполняем пропуски в числовых колонках медианой\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# Используем One-hot encoding вместо Label Encoding\n",
        "# Это поможет дереву лучше делить категории, не привязываясь к порядку чисел\n",
        "df = pd.get_dummies(df, columns=['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'], drop_first=False)\n",
        "\n",
        "# Разделяем на признаки и целевой класс\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "print(f\"Количество признаков после One-hot: {X.shape[1]}\")\n",
        "\n",
        "# Train/test разделение\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Нормализуем данные\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Обучаем дерево\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания\n",
        "y_pred = dt.predict(X_test)\n",
        "y_pred_proba = dt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Метрики\n",
        "print(\"Гипотеза 1: препроцессинг\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTINdOwAJ2DD",
        "outputId": "cbe9dbd0-ac92-4bbd-91b1-8811bbc4ef00"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "До удаления выбросов: 32581\n",
            "После удаления выбросов: 31679\n",
            "Количество признаков после One-hot: 26\n",
            "Гипотеза 1: препроцессинг\n",
            "Accuracy: 0.8966\n",
            "Precision: 0.7489\n",
            "Recall: 0.7824\n",
            "F1-Score: 0.7653\n",
            "ROC-AUC: 0.8552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 1:**\n",
        "\n",
        "Препроцессинг снова сработал. Метрики чуть подросли, One-Hot Encoding помог дереву лучше разделять категории кредитов, а удаление выбросов убрало шум. Точность почти не изменилась, но общий F1-Score подрос.\n",
        "\n",
        "Гипотезу 1 принимаем, оставляем эту обработку данных.\n",
        "\n"
      ],
      "metadata": {
        "id": "i6LB1vaWKpEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Гипотеза 2: подбираем глубину дерева и размер листа\n",
        "# Берём несколько разумных значений max_depth и min_samples_leaf\n",
        "max_depth_values = [3, 5, 7, 10, 12, 15]\n",
        "min_samples_leaf_values = [1, 2, 5, 10]\n",
        "\n",
        "results = []\n",
        "\n",
        "print(\"Подбор гиперпараметров для дерева (5-fold CV по F1):\\n\")\n",
        "\n",
        "for max_depth in max_depth_values:\n",
        "    for min_samples_leaf in min_samples_leaf_values:\n",
        "        # Создаём дерево с заданными параметрами\n",
        "        dt = DecisionTreeClassifier(\n",
        "            random_state=42,\n",
        "            criterion='gini',\n",
        "            max_depth=max_depth,\n",
        "            min_samples_leaf=min_samples_leaf\n",
        "        )\n",
        "\n",
        "        # Считаем F1-Score на кросс-валидации (5 фолдов)\n",
        "        cv_scores = cross_val_score(dt, X_train, y_train, cv=5, scoring='f1')\n",
        "        mean_score = cv_scores.mean()\n",
        "\n",
        "        results.append({\n",
        "            'max_depth': max_depth,\n",
        "            'min_samples_leaf': min_samples_leaf,\n",
        "            'mean_f1': mean_score\n",
        "        })\n",
        "\n",
        "        print(f\"max_depth={max_depth:2d}, min_samples_leaf={min_samples_leaf:2d}: \"\n",
        "              f\"F1 (5-fold CV) = {mean_score:.4f}\")\n",
        "\n",
        "# Находим лучшую комбинацию по среднему F1\n",
        "best = max(results, key=lambda x: x['mean_f1'])\n",
        "best_max_depth = best['max_depth']\n",
        "best_min_samples_leaf = best['min_samples_leaf']\n",
        "best_f1_cv = best['mean_f1']\n",
        "\n",
        "print(f\"\\nЛучшие параметры:\")\n",
        "print(f\"max_depth = {best_max_depth}, min_samples_leaf = {best_min_samples_leaf}\")\n",
        "print(f\"Лучший F1 на кросс-валидации: {best_f1_cv:.4f}\")\n",
        "\n",
        "# Обучаем финальную модель с лучшими параметрами на всей train-выборке\n",
        "dt_best = DecisionTreeClassifier(\n",
        "    random_state=42,\n",
        "    criterion='gini',\n",
        "    max_depth=best_max_depth,\n",
        "    min_samples_leaf=best_min_samples_leaf\n",
        ")\n",
        "dt_best.fit(X_train, y_train)\n",
        "\n",
        "# Делаем предсказания на тесте\n",
        "y_pred = dt_best.predict(X_test)\n",
        "y_pred_proba = dt_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nГипотеза 2: подобранные гиперпараметры\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHtqV09eKqfS",
        "outputId": "b4e560b3-d10d-4183-dd1c-ae41852f032d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Подбор гиперпараметров для дерева (5-fold CV по F1):\n",
            "\n",
            "max_depth= 3, min_samples_leaf= 1: F1 (5-fold CV) = 0.6745\n",
            "max_depth= 3, min_samples_leaf= 2: F1 (5-fold CV) = 0.6745\n",
            "max_depth= 3, min_samples_leaf= 5: F1 (5-fold CV) = 0.6745\n",
            "max_depth= 3, min_samples_leaf=10: F1 (5-fold CV) = 0.6745\n",
            "max_depth= 5, min_samples_leaf= 1: F1 (5-fold CV) = 0.7325\n",
            "max_depth= 5, min_samples_leaf= 2: F1 (5-fold CV) = 0.7325\n",
            "max_depth= 5, min_samples_leaf= 5: F1 (5-fold CV) = 0.7325\n",
            "max_depth= 5, min_samples_leaf=10: F1 (5-fold CV) = 0.7327\n",
            "max_depth= 7, min_samples_leaf= 1: F1 (5-fold CV) = 0.7972\n",
            "max_depth= 7, min_samples_leaf= 2: F1 (5-fold CV) = 0.7974\n",
            "max_depth= 7, min_samples_leaf= 5: F1 (5-fold CV) = 0.7946\n",
            "max_depth= 7, min_samples_leaf=10: F1 (5-fold CV) = 0.7934\n",
            "max_depth=10, min_samples_leaf= 1: F1 (5-fold CV) = 0.8054\n",
            "max_depth=10, min_samples_leaf= 2: F1 (5-fold CV) = 0.8045\n",
            "max_depth=10, min_samples_leaf= 5: F1 (5-fold CV) = 0.8011\n",
            "max_depth=10, min_samples_leaf=10: F1 (5-fold CV) = 0.7963\n",
            "max_depth=12, min_samples_leaf= 1: F1 (5-fold CV) = 0.8014\n",
            "max_depth=12, min_samples_leaf= 2: F1 (5-fold CV) = 0.8014\n",
            "max_depth=12, min_samples_leaf= 5: F1 (5-fold CV) = 0.7978\n",
            "max_depth=12, min_samples_leaf=10: F1 (5-fold CV) = 0.7959\n",
            "max_depth=15, min_samples_leaf= 1: F1 (5-fold CV) = 0.7992\n",
            "max_depth=15, min_samples_leaf= 2: F1 (5-fold CV) = 0.7980\n",
            "max_depth=15, min_samples_leaf= 5: F1 (5-fold CV) = 0.7976\n",
            "max_depth=15, min_samples_leaf=10: F1 (5-fold CV) = 0.7955\n",
            "\n",
            "Лучшие параметры:\n",
            "max_depth = 10, min_samples_leaf = 1\n",
            "Лучший F1 на кросс-валидации: 0.8054\n",
            "\n",
            "Гипотеза 2: подобранные гиперпараметры\n",
            "Accuracy: 0.9351\n",
            "Precision: 0.9676\n",
            "Recall: 0.7231\n",
            "F1-Score: 0.8277\n",
            "ROC-AUC: 0.9146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Выводы по гипотезе 2:**\n",
        "\n",
        "Precision вырос до 97% с 75%. Это значит, что если мы банк, то мы не отказываем зря хорошим клиентам. ​Остальные метрики тоже подросли, кроме Recall, он немного упал (с 78% до 72%), но это ожидаемая плата за такую высокую точность.\n",
        "\n",
        "Гипотеза 2 подтверждена, ограничение глубины убрало переобучение."
      ],
      "metadata": {
        "id": "95u9QpyPL6cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 3: удаление признаков с нулевой важностью\n",
        "# Посмотрим, какие признаки наша лучшая модель (dt_best) считает важными, а какие нет\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Нам нужны названия колонок, так как X_train сейчас это numpy array\n",
        "# Берем их из датафрейма X\n",
        "feature_names = X.columns\n",
        "\n",
        "# Получаем важность признаков из обученной модели\n",
        "importances = dt_best.feature_importances_\n",
        "\n",
        "# Собираем все в табличку для наглядности\n",
        "feature_imp = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "feature_imp = feature_imp.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"Топ-10 самых важных признаков:\")\n",
        "print(feature_imp.head(10))\n",
        "\n",
        "# Находим признаки, у которых важность ровно 0\n",
        "zero_imp_features = feature_imp[feature_imp['Importance'] == 0]['Feature'].tolist()\n",
        "\n",
        "print(f\"\\nПризнаки с нулевой важностью ({len(zero_imp_features)} шт): {zero_imp_features}\")\n",
        "\n",
        "# Если такие есть, удаляем их и обучаем заново\n",
        "if len(zero_imp_features) > 0:\n",
        "    print(\"\\nУдаляем мусорные признаки и переобучаем...\")\n",
        "\n",
        "    # Чтобы удалить колонки по имени, удобнее вернуть данные в DataFrame\n",
        "    X_train_df = pd.DataFrame(X_train, columns=feature_names)\n",
        "    X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
        "\n",
        "    X_train_opt = X_train_df.drop(columns=zero_imp_features)\n",
        "    X_test_opt = X_test_df.drop(columns=zero_imp_features)\n",
        "\n",
        "    # Обучаем модель с теми же лучшими параметрами (max_depth=10, min_samples_leaf=1)\n",
        "    dt_fs = DecisionTreeClassifier(\n",
        "        random_state=42,\n",
        "        criterion='gini',\n",
        "        max_depth=10,\n",
        "        min_samples_leaf=1\n",
        "    )\n",
        "    dt_fs.fit(X_train_opt, y_train)\n",
        "\n",
        "    # Предсказания\n",
        "    y_pred = dt_fs.predict(X_test_opt)\n",
        "    y_pred_proba = dt_fs.predict_proba(X_test_opt)[:, 1]\n",
        "\n",
        "    print(\"Гипотеза 3: удаление неважных признаков\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "else:\n",
        "    print(\"\\nВсе признаки важны, удалять нечего.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwroOVIwL7vI",
        "outputId": "1ff67003-d951-4c7f-fdbe-286a4dcbad24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ-10 самых важных признаков:\n",
            "                          Feature  Importance\n",
            "5             loan_percent_income    0.295080\n",
            "10     person_home_ownership_RENT    0.182040\n",
            "4                   loan_int_rate    0.166972\n",
            "1                   person_income    0.095018\n",
            "14            loan_intent_MEDICAL    0.049636\n",
            "11  loan_intent_DEBTCONSOLIDATION    0.043614\n",
            "20                   loan_grade_D    0.037265\n",
            "2               person_emp_length    0.036138\n",
            "19                   loan_grade_C    0.026929\n",
            "9       person_home_ownership_OWN    0.012445\n",
            "\n",
            "Признаки с нулевой важностью (2 шт): ['loan_grade_B', 'cb_person_default_on_file_Y']\n",
            "\n",
            "Удаляем мусорные признаки и переобучаем...\n",
            "Гипотеза 3: удаление неважных признаков\n",
            "Accuracy: 0.9345\n",
            "Precision: 0.9657\n",
            "Recall: 0.7216\n",
            "F1-Score: 0.8260\n",
            "ROC-AUC: 0.9130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по Гипотезе 3:**\n",
        "\n",
        "Удаление признаков с нулевой важностью немного ухудшило результат. Все метрики упали на сотые доли процента.\n",
        "\n",
        "Гипотезу 3 отвергаем."
      ],
      "metadata": {
        "id": "pvrL6j6ZMZjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 4: балансировка классов (class_weight='balanced')\n",
        "# Используем лучшие параметры глубины (max_depth=10), чтобы видеть чистый эффект балансировки\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Обучаем модель с балансировкой\n",
        "dt_balanced = DecisionTreeClassifier(\n",
        "    random_state=42,\n",
        "    criterion='gini',\n",
        "    max_depth=10,          # Оставляем лучшую глубину\n",
        "    min_samples_leaf=1,\n",
        "    class_weight='balanced' # Включаем балансировку\n",
        ")\n",
        "\n",
        "dt_balanced.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания\n",
        "y_pred = dt_balanced.predict(X_test)\n",
        "y_pred_proba = dt_balanced.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Гипотеза 4: балансировка классов (class_weight='balanced')\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oPd0sKuMvig",
        "outputId": "bb756a4b-7b80-4004-f67e-aadb3cba99b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Гипотеза 4: балансировка классов (class_weight='balanced')\n",
            "Accuracy: 0.9130\n",
            "Precision: 0.8314\n",
            "Recall: 0.7480\n",
            "F1-Score: 0.7875\n",
            "ROC-AUC: 0.9087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по Гипотезе 4:**\n",
        "\n",
        "Как и ожидалось, class_weight='balanced' изменил баланс сил, но общий результат ухудшился.\n",
        "\n",
        "Гипотезу 4 не берём."
      ],
      "metadata": {
        "id": "MUyPQCxvM5e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Собираем итоговую модель на основе лучших гипотез\n",
        "# Гипотеза 1 (Препроцессинг) + гипотеза 2 (max_depth=10)\n",
        "\n",
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Удаляем выбросы\n",
        "df = df[(df['person_age'] < 100) & (df['person_emp_length'] < 100)]\n",
        "\n",
        "# Заполняем пропуски в числовых колонках\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# One-hot encoding работает лучше, чем Label Encoding\n",
        "df = pd.get_dummies(df, columns=['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'], drop_first=False)\n",
        "\n",
        "# Разделяем на признаки и целевой класс\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "# Train/test разделение\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Нормализуем данные\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Обучаем модель с лучшими параметрами (max_depth=10)\n",
        "dt_improved = DecisionTreeClassifier(\n",
        "    random_state=42,\n",
        "    criterion='gini',\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=1\n",
        ")\n",
        "dt_improved.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания\n",
        "y_pred = dt_improved.predict(X_test)\n",
        "y_pred_proba = dt_improved.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Метрики\n",
        "print(\"Улучшенный бейзлайн\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fZzKTDUNjbX",
        "outputId": "e7b265ca-f6e5-4a85-e584-98a7ff2a94f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Улучшенный бейзлайн\n",
            "Accuracy: 0.9351\n",
            "Precision: 0.9676\n",
            "Recall: 0.7231\n",
            "F1-Score: 0.8277\n",
            "ROC-AUC: 0.9146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f. Сравнение результатов с пунктом 2**\n",
        "\n",
        "Accuracy выросла с 0.8920 до 0.9351\n",
        "\n",
        "Precision вырос сильнее всего с 0.7462 до 0.9676\n",
        "\n",
        "Recall немного просел с 0.7651 до 0.7231\n",
        "\n",
        "F1-Score поднялся с 0.7556 до 0.8277\n",
        "\n",
        "ROC-AUC вырос с 0.8462 до 0.9146\n",
        "\n",
        "Все показатели выросли кроме Recall."
      ],
      "metadata": {
        "id": "SW0_bjYQOief"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**g. Выводы**\n",
        "\n",
        "Проведенные эксперименты показали, что решающее дерево очень чувствительно к настройке гиперпараметров. Борьба с переобучением удалась. Ограничение глубины дерева до 10 уровней дало самый значимый эффект. Precision взлетел почти до 97%, что говорит о высокой надежности предсказаний дефолта. AUC-ROC перелетел за 90%, это уже говорит о многом. Пришлось обменять Recall на Precision, он снизился на 4%, а F1-Score поднялся на 7%, мне этот обмен показался выгодным. Обмен Recall на Precision.\n"
      ],
      "metadata": {
        "id": "-YqJyl1jOElR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Имплементация алгоритма машинного обучения"
      ],
      "metadata": {
        "id": "lEfcDZNUTENS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Имлементация решающего дерева**"
      ],
      "metadata": {
        "id": "x37gKswWTKrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class Node:\n",
        "\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
        "        self.feature = feature          # Индекс признака\n",
        "        self.threshold = threshold      # Порог разбиения\n",
        "        self.left = left                # Левое поддерево\n",
        "        self.right = right              # Правое поддерево\n",
        "        self.value = value              # Значение класса (если лист)\n",
        "\n",
        "    def is_leaf_node(self):\n",
        "        return self.value is not None\n",
        "\n",
        "\n",
        "class CustomDecisionTree:\n",
        "\n",
        "    def __init__(self, min_samples_split=2, max_depth=100, criterion='gini'):\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.criterion = criterion  # 'gini' или 'entropy'\n",
        "        self.root = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Обучение модели\"\"\"\n",
        "        # Преобразуем в numpy, если пришли DataFrame/Series\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "\n",
        "        self.n_samples, self.n_features = X.shape\n",
        "        self.root = self._grow_tree(X, y)\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        n_labels = len(np.unique(y))\n",
        "\n",
        "        # Критерии остановки:\n",
        "        # 1. Достигли макс. глубины\n",
        "        # 2. Только один класс в узле\n",
        "        # 3. Слишком мало сэмплов для разбиения\n",
        "        if (depth >= self.max_depth or n_labels == 1 or n_samples < self.min_samples_split):\n",
        "            leaf_value = self._most_common_label(y)\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        # Жадный поиск лучшего разбиения\n",
        "        best_feat, best_thresh = self._best_split(X, y, n_features)\n",
        "\n",
        "        # Если не нашли, делаем лист\n",
        "        if best_feat is None:\n",
        "            leaf_value = self._most_common_label(y)\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        # Рекурсивно строим детей\n",
        "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n",
        "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
        "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
        "\n",
        "        return Node(best_feat, best_thresh, left, right)\n",
        "\n",
        "    def _best_split(self, X, y, n_features):\n",
        "        best_gain = -1\n",
        "        split_idx, split_threshold = None, None\n",
        "\n",
        "        for feat_idx in range(n_features):\n",
        "            X_column = X[:, feat_idx]\n",
        "            thresholds = np.unique(X_column) # Перебираем уникальные значения как пороги\n",
        "\n",
        "            for thr in thresholds:\n",
        "                gain = self._information_gain(y, X_column, thr)\n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    split_idx = feat_idx\n",
        "                    split_threshold = thr\n",
        "\n",
        "        return split_idx, split_threshold\n",
        "\n",
        "    def _information_gain(self, y, X_column, threshold):\n",
        "        # 1. Считаем impurity родителя\n",
        "        if self.criterion == 'gini':\n",
        "            parent_loss = self._gini(y)\n",
        "        else:\n",
        "            parent_loss = self._entropy(y)\n",
        "\n",
        "        # 2. Делим\n",
        "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
        "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
        "            return 0\n",
        "\n",
        "        # 3. Взвешенная impurity детей\n",
        "        n = len(y)\n",
        "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
        "\n",
        "        if self.criterion == 'gini':\n",
        "            e_l, e_r = self._gini(y[left_idxs]), self._gini(y[right_idxs])\n",
        "        else:\n",
        "            e_l, e_r = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
        "\n",
        "        child_loss = (n_l / n) * e_l + (n_r / n) * e_r\n",
        "\n",
        "        # Gain = Родитель - Дети\n",
        "        ig = parent_loss - child_loss\n",
        "        return ig\n",
        "\n",
        "    def _split(self, X_column, split_thresh):\n",
        "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
        "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
        "        return left_idxs, right_idxs\n",
        "\n",
        "    def _gini(self, y):\n",
        "        # Gini impurity: 1 - sum(p^2)\n",
        "        probas = np.bincount(y) / len(y)\n",
        "        return 1 - np.sum([p**2 for p in probas])\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        # Entropy: -sum(p * log2(p))\n",
        "        probas = np.bincount(y) / len(y)\n",
        "        return -np.sum([p * np.log2(p) for p in probas if p > 0])\n",
        "\n",
        "    def _most_common_label(self, y):\n",
        "        counter = Counter(y)\n",
        "        return counter.most_common(1)[0][0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        return np.array([self._predict_one(x, self.root) for x in X])\n",
        "\n",
        "    def _predict_one(self, x, node):\n",
        "        if node.is_leaf_node():\n",
        "            return node.value\n",
        "\n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self._predict_one(x, node.left)\n",
        "        else:\n",
        "            return self._predict_one(x, node.right)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        # Заглушка для совместимости: возвращает 0 или 1\n",
        "        preds = self.predict(X)\n",
        "        return np.column_stack((1-preds, preds))\n",
        "\n",
        "    def print_tree(self, node=None, depth=0):\n",
        "        \"\"\"\n",
        "        Метод для визуализации дерева в текстовом виде\n",
        "        \"\"\"\n",
        "        if node is None:\n",
        "            node = self.root\n",
        "\n",
        "        if node.is_leaf_node():\n",
        "            print(f\"{'  '*depth}Predict: {node.value}\")\n",
        "            return\n",
        "\n",
        "        print(f\"{'  '*depth}Feature_{node.feature} <= {node.threshold:.3f}?\")\n",
        "        self.print_tree(node.left, depth + 1)\n",
        "        self.print_tree(node.right, depth + 1)"
      ],
      "metadata": {
        "id": "JDY1Qi-ETRRX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Обучение имплементированной модели с базовым бейзлайном**"
      ],
      "metadata": {
        "id": "mFagoDv8R4Ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_base = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Переводим категории в цифры LabelEncoder-ом\n",
        "for col in ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']:\n",
        "    le = LabelEncoder()\n",
        "    df_base[col] = le.fit_transform(df_base[col])\n",
        "\n",
        "# Заполняем пропуски медианой\n",
        "df_base = df_base.fillna(df_base.median())\n",
        "\n",
        "# Делим на X и y\n",
        "X_base = df_base.drop('loan_status', axis=1)\n",
        "y_base = df_base['loan_status']\n",
        "\n",
        "# Разбиваем на трейн и тест\n",
        "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X_base, y_base, test_size=0.2, random_state=42, stratify=y_base)\n",
        "\n",
        "# Масштабируем\n",
        "scaler_base = StandardScaler()\n",
        "X_train_base = scaler_base.fit_transform(X_train_base)\n",
        "X_test_base = scaler_base.transform(X_test_base)\n",
        "\n",
        "# Обучаем наше дерево\n",
        "# Ставим глубину 20, чтобы оно не росло бесконечно (иначе будем ждать до утра)\n",
        "print(\"Обучение начато\")\n",
        "my_tree_base = CustomDecisionTree(max_depth=20, criterion='gini')\n",
        "my_tree_base.fit(X_train_base, y_train_base)\n",
        "print(\"Обучение закончено\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbz1JoREU_5S",
        "outputId": "9a8448b2-6966-49e8-d5dc-c9c51eea00b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение начато\n",
            "Обучение закончено\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c. Оценка качества имплементированной модели с базовым бейзлайном**"
      ],
      "metadata": {
        "id": "WTHuBffzTJ0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Проверяем, как оно работает на тесте\n",
        "y_pred_base_custom = my_tree_base.predict(X_test_base)\n",
        "\n",
        "# Для ROC-AUC нужны вероятности, но мой класс возвращает просто классы (0/1)\n",
        "# Сделал заглушку predict_proba, которая вернет просто 0 и 1\n",
        "y_pred_proba_base_custom = my_tree_base.predict_proba(X_test_base)[:, 1]\n",
        "\n",
        "print(\"Имплементированное дерево (базовый бейзлайн)\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_base, y_pred_base_custom):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_base, y_pred_base_custom):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_base, y_pred_base_custom):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test_base, y_pred_base_custom):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test_base, y_pred_proba_base_custom):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRDDXQ9RWoX7",
        "outputId": "d03e9825-3817-4f89-8743-ba644da852d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Имплементированное дерево (базовый бейзлайн)\n",
            "Accuracy: 0.8998\n",
            "Precision: 0.7788\n",
            "Recall: 0.7553\n",
            "F1-Score: 0.7669\n",
            "ROC-AUC: 0.8477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d. Сравнение результатов с пунктом 2**\n",
        "\n",
        "Accuracy у моей модели получилась 0.8998, что даже чуть выше, чем у sklearn (0.8920). Разница меньше процента, но приятно.\n",
        "\n",
        "Precision тоже оказался выше: 0.7788 против 0.7462.\n",
        "\n",
        "Recall, наоборот, немного ниже: 0.7553 у меня против 0.7651 у sklearn. Библиотечное дерево нашло чуть больше реальных должников.\n",
        "\n",
        "F1-Score у имплементированного дерева: 0.7669, а было 0.7556. В целом, качество практически идентичное."
      ],
      "metadata": {
        "id": "lutFPFf4XFZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e. Выводы**\n",
        "\n",
        "Цифры показывают, что алгоритм реализован правильно. Результаты почти один в один совпадают с библиотечными. То, что моя модель показала себя даже капельку лучше по точности, скорее всего связано с тем, что я поставил ограничение глубины 20, а sklearn строит дерево бесконечно, пока не запомнит все данные. Единственный минус это то, что моя модель учится дольше."
      ],
      "metadata": {
        "id": "5Tjb8OCUXKhS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f., g., и h. Добавление техник из улучшенного бейзлайна, обучение и оценка качества имплементированной модели**"
      ],
      "metadata": {
        "id": "CcrFDFU5Xwip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Используем данные из улучшенного бейзлайна\n",
        "# Они уже у нас есть в переменных X_train, y_train, X_test, y_test (почищенные и закодированные)\n",
        "\n",
        "# Конвертируем в numpy\n",
        "X_train_impr = np.array(X_train)\n",
        "X_test_impr = np.array(X_test)\n",
        "y_train_impr = np.array(y_train)\n",
        "y_test_impr = np.array(y_test)\n",
        "\n",
        "print(\"Обучаем дерево с (max_depth=10)\")\n",
        "\n",
        "# Создаем модель с лучшим гиперпараметром, который мы нашли в гипотезе 2\n",
        "my_tree_improved = CustomDecisionTree(\n",
        "    max_depth=10,        # Ограничиваем глубину, чтобы не переобучалась\n",
        "    criterion='gini',\n",
        "    min_samples_split=2\n",
        ")\n",
        "\n",
        "# Обучаем\n",
        "my_tree_improved.fit(X_train_impr, y_train_impr)\n",
        "print(\"Обучение завершено\")\n",
        "\n",
        "# Предсказания\n",
        "y_pred_custom_impr = my_tree_improved.predict(X_test_impr)\n",
        "y_pred_proba_custom_impr = my_tree_improved.predict_proba(X_test_impr)[:, 1]\n",
        "\n",
        "# Оценка качества\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "print(\"\\nИмплементированное дерево с улучшениями\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_custom_impr):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_custom_impr):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_custom_impr):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred_custom_impr):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_custom_impr):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASPVIIaHXzod",
        "outputId": "f41f859f-3862-4d88-b1fa-04e775ea996a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучаем дерево с (max_depth=10)\n",
            "Обучение завершено\n",
            "\n",
            "Имплементированное дерево с улучшениями\n",
            "Accuracy: 0.9342\n",
            "Precision: 0.9620\n",
            "Recall: 0.7231\n",
            "F1-Score: 0.8256\n",
            "ROC-AUC: 0.8576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**i. Сравнение результатов с пунктом 3**\n",
        "\n",
        "Результаты моей имплементации практически полностью совпали с улучшенным бейзлайном из sklearn. Accuracy у меня 0.9342, у sklearn было 0.9351, разницы почти нет. Precision у моей модели 0.9620, у sklearn 0.9676. Оба значения высокие. Recall совпал почти идеально: 0.7231 в обоих случаях. Это значит, что структура дерева получилась вполне идентичной."
      ],
      "metadata": {
        "id": "qjJ3V4oMYpne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**j. Выводы**\n",
        "\n",
        "Моя реализация решающего дерева справилась с задачей. Всё работает, при тех же данных и тех же параметрах (max_depth=10) она выдает результаты идентичные библиотеке sklearn."
      ],
      "metadata": {
        "id": "wEeBUDdkYzWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Регрессия"
      ],
      "metadata": {
        "id": "osCx13Bxi4Pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Создание бейзлайна и оценка качества"
      ],
      "metadata": {
        "id": "sI3mVlgvjV8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Обучение модели sklearn**"
      ],
      "metadata": {
        "id": "D6bBjEndjfAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Загружаем датасет\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "\n",
        "# Удаляем лишнее\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# Кодируем текстовые признаки\n",
        "for col in ['Company_Name', 'Job_Role', 'Experience_Level', 'City']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Заполняем пропуски медианой\n",
        "df = df.fillna(df.median())\n",
        "\n",
        "# Разделяем на признаки и целевую переменную\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "# Train/test разделение\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Нормализуем данные\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Обучаем дерево регрессии\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "dt_reg.fit(X_train, y_train)\n",
        "\n",
        "# Предсказываем\n",
        "y_pred = dt_reg.predict(X_test)\n",
        "\n",
        "# Метрики\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "print(\"Дерево решений (Бейзлайн)\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6kfUF2bjgY0",
        "outputId": "38f90429-1d7f-47fc-acb5-3c0f9803b8db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дерево решений (Бейзлайн)\n",
            "MAE: 546925.29\n",
            "RMSE: 736133.63\n",
            "R²: 0.1392\n",
            "MAPE: 51.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Оценка качества модели**\n",
        "\n",
        "Базовая модель дерева решений показала слабые результаты. Коэффициент детерминации R² равен всего 0.1392, что говорит о том, что модель почти не улавливает закономерности в данных и работает чуть лучше, чем простое предсказание средней зарплаты. Средняя ошибка в процентах составляет 51%, это очень много. Если человек реально получает 100 тысяч, модель может предсказать и 50, и 150 тысяч. Причины такого провала, я думаю, в переобучении."
      ],
      "metadata": {
        "id": "mSj5-i3xj7sn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Улучшение бейзлайна"
      ],
      "metadata": {
        "id": "6JMy6VWVkFKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Формулирование гипотез**\n",
        "\n",
        "**Гипотеза 1: Препроцессинг**\n",
        "\n",
        "Признак Experience_Level (опыт работы) имеет явный порядок: \"0-1 years\" < \"1-3 years\" < \"5-8 years\" и т.д. LabelEncoder кодирует их алфавитно, из-за чего \"12+ years\" может оказаться меньше, чем \"3-5 years\".\n",
        "Идея: Закодировать опыт вручную по возрастанию (0, 1, 2...), а для остальных категорий (город и компания) использовать One-Hot Encoding. Плюс удалить выбросы по зарплате.\n",
        "\n",
        "**Гипотеза 2: Ограничение глубины дерева**\n",
        "\n",
        "Как и в классификации, дерево регрессии без тормозов начинает подстраиваться под каждую уникальную зарплату, теряя способность обобщать. Можно подобрать оптимальную глубину и минимальное число примеров в листе через кросс-валидацию, чтобы модель искала общие тренды, а не запоминала частные случаи.\n",
        "\n",
        "**Гипотеза 3: Логарифмирование целевой переменной**\n",
        "\n",
        "Много людей с маленькой зарплатой и мало с огромной. Это мешает модели минимизировать квадратичную ошибку.Можно Обучать модель предсказывать не Salary, а log(Salary). Это должно сделать распределение более нормальным и снизить влияние гигантских зарплат на обучение.\n",
        "\n",
        "**Гипотеза 4: Подбор критерия разбиения**\n",
        "\n",
        "В DecisionTreeRegressor можно менять критерий разбиения: squared_error (MSE, стандартный) или absolute_error (MAE). Попробуем оба и посмотрим, какой даст лучшую MAPE.\n",
        "\n"
      ],
      "metadata": {
        "id": "qH3n-izDkKSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Проверка гипотез**"
      ],
      "metadata": {
        "id": "caat_gRKkwCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# 1. Удаляем жесткие выбросы по зарплате (берем 1% и 99% квантили)\n",
        "# Это уберет аномально низкие и аномально высокие зарплаты, которые сбивают модель\n",
        "q_low = df['Salary_INR'].quantile(0.01)\n",
        "q_high = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q_low) & (df['Salary_INR'] <= q_high)]\n",
        "\n",
        "# 2. Правильное кодирование опыта\n",
        "# Создаем словарь, чтобы задать порядок. Если каких-то категорий нет в датасете, код не упадет.\n",
        "experience_map = {\n",
        "    '0-1 years': 0,\n",
        "    '1-3 years': 1,\n",
        "    '3-5 years': 2,\n",
        "    '5-8 years': 3,\n",
        "    '8-12 years': 4,\n",
        "    '12+ years': 5\n",
        "}\n",
        "# map заменит строки на числа. Если вдруг встретится что-то новое, заполнится NaN\n",
        "df['Experience_Level'] = df['Experience_Level'].map(experience_map)\n",
        "\n",
        "# 3. Заполняем пропуски\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# 4. One-Hot Encoding для остальных категорий\n",
        "# drop_first=True не обязательно для дерева, но уменьшает кол-во колонок\n",
        "df = pd.get_dummies(df, columns=['Company_Name', 'Job_Role', 'City'], drop_first=False)\n",
        "\n",
        "# Разделяем\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "# Train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Нормализация\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Обучаем дерево\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "dt_reg.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания\n",
        "y_pred = dt_reg.predict(X_test)\n",
        "\n",
        "# Метрики\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "print(\"Гипотеза 1: Препроцессинг\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjtLtMCxkzuJ",
        "outputId": "19c55c2e-2613-4829-a49d-5d3165ab2ab8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Гипотеза 1: Препроцессинг\n",
            "MAE: 521602.46\n",
            "RMSE: 695136.27\n",
            "R²: 0.0796\n",
            "MAPE: 49.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 1:**\n",
        "\n",
        "Хоть R² и просел, но MAE и RMSE уменьшились.\n",
        "\n",
        "Гипотеза 1 подтверждена."
      ],
      "metadata": {
        "id": "V9rzlV7Tl8po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Сетка параметров\n",
        "# В регрессии min_samples_leaf обычно нужно брать побольше, чтобы сглаживать предсказания\n",
        "param_grid = {\n",
        "    'max_depth': [5, 10, 15, 20, None],\n",
        "    'min_samples_leaf': [1, 5, 10, 20, 50]\n",
        "}\n",
        "\n",
        "print(\"Подбор гиперпараметров для регрессии\")\n",
        "\n",
        "# Используем GridSearch\n",
        "grid_search = GridSearchCV(\n",
        "    DecisionTreeRegressor(random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
        "\n",
        "# Обучаем лучшую модель\n",
        "dt_best = grid_search.best_estimator_\n",
        "\n",
        "# Предсказания\n",
        "y_pred = dt_best.predict(X_test)\n",
        "\n",
        "# Метрики\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "print(\"\\nГипотеза 2: Подбор глубины\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSgdKMOKlwI2",
        "outputId": "4fe333de-b674-4e61-a190-0a2ce5ca86d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Подбор гиперпараметров для регрессии\n",
            "Лучшие параметры: {'max_depth': 10, 'min_samples_leaf': 50}\n",
            "\n",
            "Гипотеза 2: Подбор глубины\n",
            "MAE: 393977.33\n",
            "RMSE: 494989.24\n",
            "R²: 0.5333\n",
            "MAPE: 39.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 2:**\n",
        "\n",
        "После подбора max_depth=10 и min_samples_leaf=50 качество заметно выросло: R² подскочил до 0.5333, то есть модель стала объяснять уже больше половины разброса зарплат. Ошибки тоже просели: MAE уменьшился примерно до 394 тысяч, а MAPE до 39.3%, то есть средняя относительная ошибка стала меньше 40%.\n",
        "\n",
        "Гипотеза 2 подтверждена."
      ],
      "metadata": {
        "id": "kAYgH7nsmeXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 3: Логарифмирование целевой переменной\n",
        "# Обучаем ту же лучшую модель (max_depth=10, min_samples_leaf=50), но на логарифмах\n",
        "\n",
        "# Логарифмируем y_train\n",
        "# Используем log1p (log(1+x)), чтобы не упасть на нулях\n",
        "y_train_log = np.log1p(y_train)\n",
        "\n",
        "# Обучаем\n",
        "dt_log = DecisionTreeRegressor(\n",
        "    random_state=42,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=50\n",
        ")\n",
        "dt_log.fit(X_train, y_train_log)\n",
        "\n",
        "# Предсказываем логарифм\n",
        "y_pred_log = dt_log.predict(X_test)\n",
        "\n",
        "# Возвращаем обратно в деньги\n",
        "# expm1 - обратная функция к log1p\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "\n",
        "# Метрики считаем по нормальным деньгам\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "print(\"Гипотеза 3: Логарифмирование таргета\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfRQxmPDmW78",
        "outputId": "8edac491-7577-42ca-a252-f6386a06a148"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Гипотеза 3: Логарифмирование таргета\n",
            "MAE: 397989.53\n",
            "RMSE: 503056.02\n",
            "R²: 0.5180\n",
            "MAPE: 36.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 3:**\n",
        "\n",
        "Хотя R² немного снизился, MAPE стала лучше: 36.87% против 39.31%. В задачах с зарплатами важнее точнее попадать в порядок сумм, чем минимизировать квадрат ошибки на миллионерах.\n",
        "\n",
        "Гипотеза 3 подтверждена."
      ],
      "metadata": {
        "id": "0eix_5AonEuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 4: Подбор критерия разбиения\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Загружаем и готовим данные\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# Удаляем выбросы\n",
        "q_low = df['Salary_INR'].quantile(0.01)\n",
        "q_high = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q_low) & (df['Salary_INR'] <= q_high)]\n",
        "\n",
        "# Кодируем опыт\n",
        "experience_map = {\n",
        "    '0-1 years': 0, '1-3 years': 1, '3-5 years': 2,\n",
        "    '5-8 years': 3, '8-12 years': 4, '12+ years': 5\n",
        "}\n",
        "df['Experience_Level'] = df['Experience_Level'].map(experience_map)\n",
        "\n",
        "# Пропуски\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# One-hot\n",
        "df = pd.get_dummies(df, columns=['Company_Name', 'Job_Role', 'City'], drop_first=False)\n",
        "\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "# Логарифмируем таргет\n",
        "y_log = np.log1p(y)\n",
        "\n",
        "# Разделяем\n",
        "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
        "\n",
        "# Нормализуем\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Тестируем два критерия\n",
        "print(\"Гипотеза 4: Сравнение критериев разбиения\\n\")\n",
        "\n",
        "# Модель 1: squared_error (MSE - стандартный)\n",
        "dt_mse = DecisionTreeRegressor(\n",
        "    random_state=42,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=50,\n",
        "    criterion='squared_error'\n",
        ")\n",
        "dt_mse.fit(X_train, y_train_log)\n",
        "y_pred_log_mse = dt_mse.predict(X_test)\n",
        "y_pred_mse = np.expm1(y_pred_log_mse)\n",
        "\n",
        "# Модель 2: absolute_error (MAE)\n",
        "dt_mae = DecisionTreeRegressor(\n",
        "    random_state=42,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=50,\n",
        "    criterion='absolute_error'\n",
        ")\n",
        "dt_mae.fit(X_train, y_train_log)\n",
        "y_pred_log_mae = dt_mae.predict(X_test)\n",
        "y_pred_mae = np.expm1(y_pred_log_mae)\n",
        "\n",
        "# Реальный таргет\n",
        "y_test_orig = np.expm1(y_test_log)\n",
        "\n",
        "# Метрики для MSE\n",
        "print(\"Criterion = 'squared_error' (MSE):\")\n",
        "mae_mse = mean_absolute_error(y_test_orig, y_pred_mse)\n",
        "rmse_mse = np.sqrt(mean_squared_error(y_test_orig, y_pred_mse))\n",
        "r2_mse = r2_score(y_test_orig, y_pred_mse)\n",
        "mape_mse = np.mean(np.abs((y_test_orig - y_pred_mse) / y_test_orig)) * 100\n",
        "print(f\"MAE: {mae_mse:.2f}\")\n",
        "print(f\"RMSE: {rmse_mse:.2f}\")\n",
        "print(f\"R²: {r2_mse:.4f}\")\n",
        "print(f\"MAPE: {mape_mse:.2f}%\")\n",
        "\n",
        "# Метрики для MAE\n",
        "print(\"\\nCriterion = 'absolute_error' (MAE):\")\n",
        "mae_mae_val = mean_absolute_error(y_test_orig, y_pred_mae)\n",
        "rmse_mae = np.sqrt(mean_squared_error(y_test_orig, y_pred_mae))\n",
        "r2_mae = r2_score(y_test_orig, y_pred_mae)\n",
        "mape_mae = np.mean(np.abs((y_test_orig - y_pred_mae) / y_test_orig)) * 100\n",
        "print(f\"MAE: {mae_mae_val:.2f}\")\n",
        "print(f\"RMSE: {rmse_mae:.2f}\")\n",
        "print(f\"R²: {r2_mae:.4f}\")\n",
        "print(f\"MAPE: {mape_mae:.2f}%\")\n",
        "\n",
        "# Вывод\n",
        "if mape_mae < mape_mse:\n",
        "    print(\"\\nГипотеза 4: criterion='absolute_error' работает лучше\")\n",
        "else:\n",
        "    print(\"\\nГипотеза 4: criterion='squared_error' остается лучшим выбором.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l9WTxzjnS-_",
        "outputId": "ae6eac6a-7a7e-4790-e9b4-c636e3a70cb7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Гипотеза 4: Сравнение критериев разбиения\n",
            "\n",
            "Criterion = 'squared_error' (MSE):\n",
            "MAE: 397989.53\n",
            "RMSE: 503056.02\n",
            "R²: 0.5180\n",
            "MAPE: 36.87%\n",
            "\n",
            "Criterion = 'absolute_error' (MAE):\n",
            "MAE: 398400.09\n",
            "RMSE: 504460.54\n",
            "R²: 0.5153\n",
            "MAPE: 39.40%\n",
            "\n",
            "Гипотеза 4: criterion='squared_error' остается лучшим выбором.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 4:**\n",
        "\n",
        "Результаты показали, что MSE работает лучше: MAPE составила 36.87% против 39.40% у MAE. Хотя MAE теоретически должен быть менее чувствителен к выбросам, на практике в нашем случае (после логарифмирования таргета и чистки данных) стандартный MSE показал себя точнее. R² и RMSE тоже чуть лучше у MSE.\n",
        "\n",
        "Гипотезу 4 отвергаем.\n"
      ],
      "metadata": {
        "id": "GQdSdnKQq4PQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c. и d. Формирование и обучение моделис улучшенным бейзлайном**"
      ],
      "metadata": {
        "id": "YOc52kwco_Cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# Удаляем выбросы по зарплате\n",
        "q_low = df['Salary_INR'].quantile(0.01)\n",
        "q_high = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q_low) & (df['Salary_INR'] <= q_high)]\n",
        "\n",
        "# Правильное кодирование опыта\n",
        "experience_map = {\n",
        "    '0-1 years': 0, '1-3 years': 1, '3-5 years': 2,\n",
        "    '5-8 years': 3, '8-12 years': 4, '12+ years': 5\n",
        "}\n",
        "df['Experience_Level'] = df['Experience_Level'].map(experience_map)\n",
        "\n",
        "# Заполняем пропуски\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# One-hot для категорий\n",
        "df = pd.get_dummies(df, columns=['Company_Name', 'Job_Role', 'City'], drop_first=False)\n",
        "\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "# Логарифмируем таргет\n",
        "y_log = np.log1p(y)\n",
        "\n",
        "# Разделение\n",
        "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.2, random_state=42)\n",
        "\n",
        "# Нормализация\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Обучаем с лучшими параметрами\n",
        "dt_improved = DecisionTreeRegressor(\n",
        "    random_state=42,\n",
        "    criterion='squared_error',\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=50\n",
        ")\n",
        "dt_improved.fit(X_train, y_train_log)\n",
        "\n",
        "# Предсказания\n",
        "y_pred_log = dt_improved.predict(X_test)\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "y_test_orig = np.expm1(y_test_log)\n",
        "\n",
        "# Метрики\n",
        "mae = mean_absolute_error(y_test_orig, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
        "r2 = r2_score(y_test_orig, y_pred)\n",
        "mape = np.mean(np.abs((y_test_orig - y_pred) / y_test_orig)) * 100\n",
        "\n",
        "print(\"Улучшенный бейзлайн\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "munF-VtQqKH-",
        "outputId": "288b3f56-51e6-4fcf-d5fe-9ddefe580f32"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Улучшенный бейзлайн\n",
            "MAE: 397989.53\n",
            "RMSE: 503056.02\n",
            "R²: 0.5180\n",
            "MAPE: 36.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f. Сравнение результатов с пунктом 2**\n",
        "\n",
        "Улучшенный бейзлайн показывает заметно лучшие результаты по сравнению с исходной моделью.\n",
        "\n",
        "MAE уменьшилась с 546 925 до 397 990 рупий. Средняя ошибка снизилась примерно на 149 тысяч.\n",
        "\n",
        "RMSE снизился с 736 134 до 503 056. Это означает, что модель стала реже допускать очень большие ошибки на высоких значениях зарплат.\n",
        "\n",
        "R² вырос с 0.14 до 0.52.\n",
        "\n",
        "MAPE уменьшился с 51% до 36.87%. Относительная ошибка сократилась на 14 процентных пунктов, и предсказания стали существенно ближе к реальным значениям.\n",
        "\n",
        "В целом улучшенный бейзлайн показывает гораздо более стабильную и точную работу по всем метрикам."
      ],
      "metadata": {
        "id": "rheCJabAqdgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**g. Выводы**\n",
        "\n",
        "Все три гипотезы оказались рабочими и улучшили модель.\n",
        "\n",
        "Корректный Ordinal Encoding помог вернуть смысл порядку уровней опыта. Ограничение глубины дерева оказалось самым полезным, модель перестала переобучаться и стала лучше обобщать данные. Логарифмирование таргета снизило перекос на больших зарплатах и уменьшило относительные ошибки.Попытка перейти на критерий MAE мне ничего не дала, MSE всё равно работал лучше.\n",
        "\n",
        "В итоге модель стала куда точнее, итоговый MAPE опустился ниже 37%, что уже подходит для реальной оценки зарплат."
      ],
      "metadata": {
        "id": "BOG8ywZcqmPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Имплементация алгоритма машинного обучения"
      ],
      "metadata": {
        "id": "8curU2f_rhjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Имплементация решающего дерева**"
      ],
      "metadata": {
        "id": "Xxafc0_ssAfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
        "        self.feature = feature          # Индекс признака\n",
        "        self.threshold = threshold      # Порог разбиения\n",
        "        self.left = left                # Левое поддерево\n",
        "        self.right = right              # Правое поддерево\n",
        "        self.value = value              # Среднее значение (если лист)\n",
        "\n",
        "    def is_leaf_node(self):\n",
        "        return self.value is not None\n",
        "\n",
        "\n",
        "class CustomDecisionTreeRegressor:\n",
        "\n",
        "\n",
        "    def __init__(self, min_samples_split=2, max_depth=100, min_samples_leaf=1, criterion='squared_error'):\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.criterion = criterion  # 'squared_error' или 'absolute_error'\n",
        "        self.root = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Обучение модели\"\"\"\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "\n",
        "        self.n_samples, self.n_features = X.shape\n",
        "        self.root = self._grow_tree(X, y)\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        n_samples = len(y)\n",
        "\n",
        "        # Критерии остановки:\n",
        "        # 1. Достигли макс. глубины\n",
        "        # 2. Слишком мало сэмплов для разбиения\n",
        "        # 3. Все значения одинаковые (дисперсия = 0)\n",
        "        if (depth >= self.max_depth or\n",
        "            n_samples < self.min_samples_split or\n",
        "            self._variance(y) < 1e-7):\n",
        "            leaf_value = self._mean_value(y)\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        # Жадный поиск лучшего разбиения\n",
        "        best_feat, best_thresh = self._best_split(X, y)\n",
        "\n",
        "        # Если не нашли (variance reduction = 0), делаем лист\n",
        "        if best_feat is None:\n",
        "            leaf_value = self._mean_value(y)\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        # Разбиваем данные\n",
        "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n",
        "\n",
        "        # Проверяем min_samples_leaf\n",
        "        if len(left_idxs) < self.min_samples_leaf or len(right_idxs) < self.min_samples_leaf:\n",
        "            leaf_value = self._mean_value(y)\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        # Рекурсивно строим детей\n",
        "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
        "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
        "\n",
        "        return Node(best_feat, best_thresh, left, right)\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        best_gain = -1\n",
        "        split_idx, split_threshold = None, None\n",
        "\n",
        "        for feat_idx in range(self.n_features):\n",
        "            X_column = X[:, feat_idx]\n",
        "            thresholds = np.unique(X_column)\n",
        "\n",
        "            for thr in thresholds:\n",
        "                gain = self._variance_reduction(y, X_column, thr)\n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    split_idx = feat_idx\n",
        "                    split_threshold = thr\n",
        "\n",
        "        return split_idx, split_threshold\n",
        "\n",
        "    def _variance_reduction(self, y, X_column, threshold):\n",
        "        # Считаем variance reduction\n",
        "\n",
        "        # Считаем \"impurity\" родителя\n",
        "        if self.criterion == 'squared_error':\n",
        "            parent_loss = self._mse(y)\n",
        "        else:\n",
        "            parent_loss = self._mae(y)\n",
        "\n",
        "        # Делим\n",
        "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
        "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
        "            return 0\n",
        "\n",
        "        # Взвешенная impurity детей\n",
        "        n = len(y)\n",
        "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
        "\n",
        "        if self.criterion == 'squared_error':\n",
        "            e_l, e_r = self._mse(y[left_idxs]), self._mse(y[right_idxs])\n",
        "        else:\n",
        "            e_l, e_r = self._mae(y[left_idxs]), self._mae(y[right_idxs])\n",
        "\n",
        "        child_loss = (n_l / n) * e_l + (n_r / n) * e_r\n",
        "\n",
        "        # Variance reduction\n",
        "        return parent_loss - child_loss\n",
        "\n",
        "    def _split(self, X_column, split_thresh):\n",
        "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
        "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
        "        return left_idxs, right_idxs\n",
        "\n",
        "    def _mse(self, y):\n",
        "        # Mean Squared Error (variance)\n",
        "        if len(y) == 0:\n",
        "            return 0\n",
        "        return np.var(y)\n",
        "\n",
        "    def _mae(self, y):\n",
        "        # Mean Absolute Error от медианы\n",
        "        if len(y) == 0:\n",
        "            return 0\n",
        "        median = np.median(y)\n",
        "        return np.mean(np.abs(y - median))\n",
        "\n",
        "    def _variance(self, y):\n",
        "        # Дисперсия (для проверки остановки)\n",
        "        return np.var(y)\n",
        "\n",
        "    def _mean_value(self, y):\n",
        "        # Среднее значение для листа\n",
        "        return np.mean(y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        return np.array([self._predict_one(x, self.root) for x in X])\n",
        "\n",
        "    def _predict_one(self, x, node):\n",
        "        if node.is_leaf_node():\n",
        "            return node.value\n",
        "\n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self._predict_one(x, node.left)\n",
        "        else:\n",
        "            return self._predict_one(x, node.right)\n",
        "\n",
        "    def print_tree(self, node=None, depth=0):\n",
        "\n",
        "        if node is None:\n",
        "            node = self.root\n",
        "\n",
        "        if node.is_leaf_node():\n",
        "            print(f\"{'  '*depth}Predict: {node.value:.2f}\")\n",
        "            return\n",
        "\n",
        "        print(f\"{'  '*depth}Feature_{node.feature} <= {node.threshold:.3f}?\")\n",
        "        self.print_tree(node.left, depth + 1)\n",
        "        self.print_tree(node.right, depth + 1)"
      ],
      "metadata": {
        "id": "mghWaTSTsFsy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Обучение и оценка качества имплементированной модели с базовым бейзлайном**"
      ],
      "metadata": {
        "id": "GVB0eJbusXLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# b. Обучение имплементированной модели (базовый бейзлайн)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Грузим данные\n",
        "df_base = pd.read_csv('Job_Market_India.csv')\n",
        "df_base = df_base.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# Кодируем все категории LabelEncoder-ом\n",
        "for col in ['Company_Name', 'Job_Role', 'Experience_Level', 'City']:\n",
        "    le = LabelEncoder()\n",
        "    df_base[col] = le.fit_transform(df_base[col])\n",
        "\n",
        "# Заполняем пропуски медианой\n",
        "df_base = df_base.fillna(df_base.median())\n",
        "\n",
        "# Делим на X и y\n",
        "X_base = df_base.drop('Salary_INR', axis=1)\n",
        "y_base = df_base['Salary_INR']\n",
        "\n",
        "# Train/test разделение\n",
        "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X_base, y_base, test_size=0.2, random_state=42)\n",
        "\n",
        "# Масштабируем\n",
        "scaler_base = StandardScaler()\n",
        "X_train_base = scaler_base.fit_transform(X_train_base)\n",
        "X_test_base = scaler_base.transform(X_test_base)\n",
        "\n",
        "# Обучаем с параметрами по умолчанию (max_depth=100, без реальных ограничений)\n",
        "print(\"Обучение начато\")\n",
        "my_tree_reg_base = CustomDecisionTreeRegressor()  # Параметры по умолчанию\n",
        "my_tree_reg_base.fit(X_train_base, y_train_base)\n",
        "print(\"Обучение завершено\")\n",
        "\n",
        "# c. Оценка качества\n",
        "y_pred_base_custom = my_tree_reg_base.predict(X_test_base)\n",
        "\n",
        "mae = mean_absolute_error(y_test_base, y_pred_base_custom)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_base, y_pred_base_custom))\n",
        "r2 = r2_score(y_test_base, y_pred_base_custom)\n",
        "mape = np.mean(np.abs((y_test_base - y_pred_base_custom) / y_test_base)) * 100\n",
        "\n",
        "print(\"\\nИмплементированное дерево (Базовый бейзлайн)\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhX2sgSBtBji",
        "outputId": "b2704800-cb1b-4c8a-e7a2-18a35adc8ed5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение начато\n",
            "Обучение завершено\n",
            "\n",
            "Имплементированное дерево (Базовый бейзлайн)\n",
            "MAE: 547452.09\n",
            "RMSE: 733285.71\n",
            "R²: 0.1459\n",
            "MAPE: 51.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d. Сравнение результатов с пунктом 2**\n",
        "\n",
        "**Имплементированный алгоритм:**\n",
        "\n",
        "MAE: 547452.09\n",
        "\n",
        "RMSE: 733285.71\n",
        "\n",
        "R²: 0.1459\n",
        "\n",
        "MAPE: 51.31%\n",
        "\n",
        "**sklearn:**\n",
        "\n",
        "MAE: 546925.29\n",
        "\n",
        "RMSE: 736133.63\n",
        "\n",
        "R²: 0.1392\n",
        "\n",
        "MAPE: 51.09%\n",
        "\n",
        "Результаты схожи."
      ],
      "metadata": {
        "id": "iJaVHfDWt1Ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e. Выводы**\n",
        "\n",
        "Алгоритм дерева регрессии реализован. Почти полное совпадение метрик с sklearn подтверждает корректность работы методов разбиения по дисперсии, расчета MSE и выбора среднего значения в листьях.\n"
      ],
      "metadata": {
        "id": "S23y8huduMIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f. и g. Добавление техник из улучшенного бейзлайна и обучение модели**"
      ],
      "metadata": {
        "id": "7u72doeQuW5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Загружаем данные\n",
        "df_improved = pd.read_csv('Job_Market_India.csv')\n",
        "df_improved = df_improved.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# 1. Удаление выбросов (IQR метод для Salary_INR)\n",
        "Q1 = df_improved['Salary_INR'].quantile(0.25)\n",
        "Q3 = df_improved['Salary_INR'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "df_improved = df_improved[(df_improved['Salary_INR'] >= lower_bound) &\n",
        "                           (df_improved['Salary_INR'] <= upper_bound)]\n",
        "\n",
        "print(f\"После удаления выбросов осталось {len(df_improved)} записей\")\n",
        "\n",
        "# 2. Создание новых признаков\n",
        "df_improved['Demand_Remote'] = df_improved['Demand_Index'] * df_improved['Remote_Option_Flag']\n",
        "\n",
        "# 3. OneHotEncoding для категориальных признаков\n",
        "df_improved = pd.get_dummies(df_improved, columns=['Company_Name', 'Job_Role', 'Experience_Level', 'City'],\n",
        "                              drop_first=True, dtype=int)\n",
        "\n",
        "# Заполняем пропуски\n",
        "df_improved = df_improved.fillna(df_improved.median())\n",
        "\n",
        "# Разделяем на X и y\n",
        "X_improved = df_improved.drop('Salary_INR', axis=1)\n",
        "y_improved = df_improved['Salary_INR']\n",
        "\n",
        "print(f\"Количество признаков после обработки: {X_improved.shape[1]}\")\n",
        "\n",
        "# Train/test split\n",
        "X_train_imp, X_test_imp, y_train_imp, y_test_imp = train_test_split(\n",
        "    X_improved, y_improved, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Масштабирование\n",
        "scaler_imp = StandardScaler()\n",
        "X_train_imp = scaler_imp.fit_transform(X_train_imp)\n",
        "X_test_imp = scaler_imp.transform(X_test_imp)\n",
        "\n",
        "print(\"\\nОбучение начато\")\n",
        "my_tree_reg_improved = CustomDecisionTreeRegressor(\n",
        "    max_depth=10,\n",
        "    min_samples_split=50,\n",
        "    min_samples_leaf=20,\n",
        "    criterion='squared_error'\n",
        ")\n",
        "my_tree_reg_improved.fit(X_train_imp, y_train_imp)\n",
        "print(\"Обучение завершено\")\n",
        "\n",
        "y_pred_imp_custom = my_tree_reg_improved.predict(X_test_imp)\n",
        "\n",
        "mae_imp = mean_absolute_error(y_test_imp, y_pred_imp_custom)\n",
        "rmse_imp = np.sqrt(mean_squared_error(y_test_imp, y_pred_imp_custom))\n",
        "r2_imp = r2_score(y_test_imp, y_pred_imp_custom)\n",
        "mape_imp = np.mean(np.abs((y_test_imp - y_pred_imp_custom) / y_test_imp)) * 100\n",
        "\n",
        "print(\"\\nИмплементированное дерево (Улучшенный бейзлайн)\")\n",
        "print(f\"MAE: {mae_imp:.2f}\")\n",
        "print(f\"RMSE: {rmse_imp:.2f}\")\n",
        "print(f\"R²: {r2_imp:.4f}\")\n",
        "print(f\"MAPE: {mape_imp:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWBiQhBrwZEG",
        "outputId": "3ab71286-7c7c-4cdf-b639-9712c094a9a1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "После удаления выбросов осталось 28389 записей\n",
            "Количество признаков после обработки: 63\n",
            "\n",
            "Обучение начато\n",
            "Обучение завершено\n",
            "\n",
            "Имплементированное дерево (Улучшенный бейзлайн)\n",
            "MAE: 366862.77\n",
            "RMSE: 444755.45\n",
            "R²: 0.4193\n",
            "MAPE: 40.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**i. Сравнение результатов с пунктом 3**\n",
        "\n",
        "**sklearn:**\n",
        "\n",
        "MAE: 397989.53\n",
        "\n",
        "RMSE: 503056.02\n",
        "\n",
        "R²: 0.5180\n",
        "\n",
        "MAPE: 36.87%\n",
        "\n",
        "**Имплементированный:**\n",
        "\n",
        "MAE: 366862.77\n",
        "\n",
        "RMSE: 444755.45\n",
        "\n",
        "R²: 0.4193\n",
        "\n",
        "MAPE: 40.25%\n",
        "\n",
        "Моя реализация показала себя немного хуже sklearn."
      ],
      "metadata": {
        "id": "MCds_AR-ux50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**j. Выводы**\n",
        "\n",
        "Моя реализация дерева на улучшенных данных работает неплохо, но sklearn всё равно лучше. Причина, думаю, в том что sklearn использует более оптимизированные алгоритмы выбора разбиений и критерии остановки."
      ],
      "metadata": {
        "id": "Br4oTkPqu37-"
      }
    }
  ]
}