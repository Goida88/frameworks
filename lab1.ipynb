{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Лабораторная работа №1 (Проведение исследований с алгоритмом KNN)"
      ],
      "metadata": {
        "id": "zmSLiFCVSJ0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Классификация"
      ],
      "metadata": {
        "id": "iGIiUzLpEOlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Выбор начальных условий"
      ],
      "metadata": {
        "id": "4v09BFrTWXGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Выбор набора данных**\n",
        "\n",
        "Я выбрал датасет **Credit Risk Dataset**, потому что мне понравилась тема - предсказание кредитного дефолта, что отлично подходит для классификации. В нём около 32к записей, то есть данных достаточно для нормального обучения модели. Табличные финансовые и демографические признаки понятные и удобны для обработки, кодирования и экспериментов с KNN и другими алгоритмами."
      ],
      "metadata": {
        "id": "0iOdXoIbA193"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c. Выбор метрик**\n",
        "\n",
        "- Accuracy - общая доля правильных предсказаний. Показывает, насколько часто модель угадывает правильно. Используем как базовый показатель качества.\n",
        "\n",
        "- Precision - доля предсказанных дефолтов, которые действительно являются дефолтами. Важна для банка, чтобы не ошибочно классифицировать добросовестных клиентов как рискованных.\n",
        "\n",
        "- Recall - доля реальных дефолтов, которые модель смогла выявить. Критична для банка, чтобы не пропустить потенциальные убытки.\n",
        "\n",
        "- F1-Score - гармоническое среднее Precision и Recall. Балансирует оба типа ошибок и особенно полезна, когда классы несбалансированы (дефолтов обычно меньше, чем успешных кредитов).\n",
        "\n",
        "- ROC-AUC - показывает способность модели различать дефолтные и недефолтные кредиты при разных порогах вероятности. Хороша для сравнения разных моделей и оценки качества ранжирования кредитов по риску."
      ],
      "metadata": {
        "id": "EN6CQxkJ5u8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Создание бейзлайна и оценка качества"
      ],
      "metadata": {
        "id": "3jE8Pj_0VXoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Обучение модели sklearn**"
      ],
      "metadata": {
        "id": "ls43EBeiViLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Кодируем категориальные признаки\n",
        "for col in ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Заполняем пропуски медианой\n",
        "df = df.fillna(df.median())\n",
        "\n",
        "# Разделяем на признаки и целевой класс\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "# Train/test разделение\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Нормализуем данные\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Обучение KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания\n",
        "y_pred = knn.predict(X_test)\n",
        "y_pred_proba = knn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Метрики\n",
        "print(\"KNN (k=5) Бейзлайн\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score:  {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_proba):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI47ewuf-9CR",
        "outputId": "b05b6f07-d6b8-4002-e6fb-17da294ad644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN (k=5) Бейзлайн\n",
            "Accuracy:  0.8716\n",
            "Precision: 0.7882\n",
            "Recall:    0.5626\n",
            "F1-Score:  0.6565\n",
            "ROC-AUC:   0.8438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Оценка качества модели**\n",
        "\n",
        "- Accuracy:  0.8716\n",
        "- Precision: 0.7882\n",
        "- Recall:    0.5626\n",
        "- F1-Score:  0.6565\n",
        "- ROC-AUC:   0.8438\n",
        "\n",
        "Результаты вполне неплохие, но низкий recall меня смущает, потому что модель пропускает почти половину реальных дефолтов, но хотя бы ROC-AUC порадовал, потому что когда я брал другой датасет, там было всё печально и пришлось переделывать. Работает неплохо, но нужны улучшения."
      ],
      "metadata": {
        "id": "__L55Lvw0HzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Улучшение бейзлайна"
      ],
      "metadata": {
        "id": "GME3IKUjV8on"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Формулировка гипотез**\n",
        "\n",
        "**Гипотеза 1: Препроцессинг**\n",
        "\n",
        "Можно удалить явные выбросы по возрасту и стажу (person_age < 100, person_emp_length < 100), заполнить пропуски в числовых колонках медианой и перейти с Label Encoding на One-hot для категориальных признаков (person_home_ownership, loan_intent, loan_grade, cb_person_default_on_file), чтобы модель корректнее работала с категориями.\n",
        "\n",
        "**Гипотеза 2: Подбор k**\n",
        "\n",
        "Перебрать разные значения k (3–30) и с помощью кросс-валидации по F1-Score выбрать то, которое даёт лучший результат на обучении.\n",
        "\n",
        "**Гипотеза 3: Балансировка классов (SMOTE)**\n",
        "\n",
        "Так как классы несбалансированы (дефолтов меньше), на тренировочной выборке применить SMOTE, чтобы выровнять классы, и заново обучить KNN с найденным оптимальным k.\n",
        "\n",
        "**Гипотеза 4: Новые признаки**\n",
        "\n",
        "Добавить признаки income_to_loan (доход / сумма кредита) и age_emp_ratio (возраст / стаж) до One-hot encoding, чтобы дать модели более содержательную информацию о клиенте."
      ],
      "metadata": {
        "id": "F6abg5u61G_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Проверка гипотез**"
      ],
      "metadata": {
        "id": "j6cEXog00_qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 1: препроцессинг (удаление выбросов + One-hot encoding)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Удаляем выбросы\n",
        "print(\"До удаления выбросов:\", len(df))\n",
        "df = df[(df['person_age'] < 100) & (df['person_emp_length'] < 100)]\n",
        "print(\"После удаления выбросов:\", len(df))\n",
        "\n",
        "# Заполняем пропуски только в числовых колонках\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# One-hot encoding для категориальных признаков\n",
        "df = pd.get_dummies(df, columns=['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'], drop_first=False)\n",
        "\n",
        "# Разделяем на признаки и целевой класс\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "print(f\"Количество признаков после One-hot: {X.shape[1]}\")\n",
        "\n",
        "# Train/test разделение\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Нормализуем данные\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Обучаем KNN с k=5\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания\n",
        "y_pred = knn.predict(X_test)\n",
        "y_pred_proba = knn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Метрики\n",
        "print(\"Гипотеза 1: препроцессинг\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score:  {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_proba):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqGVtdRJBlD4",
        "outputId": "6c228860-0719-42d9-b856-ac7e6b9d73c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "До удаления выбросов: 32581\n",
            "После удаления выбросов: 31679\n",
            "Количество признаков после One-hot: 26\n",
            "Гипотеза 1: препроцессинг\n",
            "Accuracy:  0.8995\n",
            "Precision: 0.8692\n",
            "Recall:    0.6278\n",
            "F1-Score:  0.7291\n",
            "ROC-AUC:   0.8662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 1:**\n",
        "\n",
        "Все метрики улучшились, удаление выбросов помогло, One-hot лучше Label, Recall подрос.\n",
        "\n",
        "Гипотеза 1 подтверждена, можно её использовать."
      ],
      "metadata": {
        "id": "gsjWid2AB78u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 2: подбор гиперпараметров (оптимальное k)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Проверяем разные значения k\n",
        "k_values = [3, 5, 7, 9, 11, 15, 20, 25, 30]\n",
        "results = []\n",
        "\n",
        "print(\"Проверка разных значений k с кросс-валидацией (5-fold):\")\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    # Кросс-валидация по F1-Score\n",
        "    cv_scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='f1')\n",
        "    mean_score = cv_scores.mean()\n",
        "    results.append({'k': k, 'mean_f1': mean_score})\n",
        "    print(f\"k={k:2d}: F1-Score (5-fold CV) = {mean_score:.4f}\")\n",
        "\n",
        "# Находим лучшее k\n",
        "best_k = max(results, key=lambda x: x['mean_f1'])['k']\n",
        "best_f1_cv = max(results, key=lambda x: x['mean_f1'])['mean_f1']\n",
        "\n",
        "print(f\"\\nЛучшее k = {best_k} (F1-Score = {best_f1_cv:.4f})\")\n",
        "\n",
        "# Обучаем KNN с лучшим k\n",
        "knn_best = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn_best.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn_best.predict(X_test)\n",
        "y_pred_proba = knn_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(f\"гипотеза 2: подбор к (k={best_k})\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score:  {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_proba):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnVjnidOCFc3",
        "outputId": "5feb4812-7cb1-4bd3-e1df-51451ea30b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Проверка разных значений k с кросс-валидацией (5-fold):\n",
            "k= 3: F1-Score (5-fold CV) = 0.7038\n",
            "k= 5: F1-Score (5-fold CV) = 0.7164\n",
            "k= 7: F1-Score (5-fold CV) = 0.7200\n",
            "k= 9: F1-Score (5-fold CV) = 0.7169\n",
            "k=11: F1-Score (5-fold CV) = 0.7140\n",
            "k=15: F1-Score (5-fold CV) = 0.7121\n",
            "k=20: F1-Score (5-fold CV) = 0.6940\n",
            "k=25: F1-Score (5-fold CV) = 0.6954\n",
            "k=30: F1-Score (5-fold CV) = 0.6773\n",
            "\n",
            "Лучшее k = 7 (F1-Score = 0.7200)\n",
            "гипотеза 2: подбор к (k=7)\n",
            "Accuracy:  0.9020\n",
            "Precision: 0.8851\n",
            "Recall:    0.6264\n",
            "F1-Score:  0.7336\n",
            "ROC-AUC:   0.8742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 2:**\n",
        "\n",
        "k=7 лучше, чем k=5, все кроме Recall подросло.\n",
        "\n",
        "Гипотеза 2 подтверждена, k=7 добавим в улучшенный бейзлайн."
      ],
      "metadata": {
        "id": "yXPdd6M4Ccs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 3: балансировка классов (SMOTE)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "print(\"Распределение классов ДО SMOTE:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "# Применяем SMOTE на тренировочных данных\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nРаспределение классов ПОСЛЕ SMOTE:\")\n",
        "print(pd.Series(y_train_smote).value_counts())\n",
        "\n",
        "# Нормализуем данные после SMOTE\n",
        "scaler = StandardScaler()\n",
        "X_train_smote = scaler.fit_transform(X_train_smote)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Обучаем KNN с k=7 (лучший k из гипотезы 2)\n",
        "knn_smote = KNeighborsClassifier(n_neighbors=7)\n",
        "knn_smote.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "y_pred = knn_smote.predict(X_test_scaled)\n",
        "y_pred_proba = knn_smote.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "print(\"гипотеза 3: SMOTE (k=7)\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score:  {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_proba):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpZnI87rDBy2",
        "outputId": "d0374100-a9ab-429e-fb45-7134a24e6b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Распределение классов ДО SMOTE:\n",
            "loan_status\n",
            "0    19883\n",
            "1     5460\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Распределение классов ПОСЛЕ SMOTE:\n",
            "loan_status\n",
            "0    19883\n",
            "1    19883\n",
            "Name: count, dtype: int64\n",
            "гипотеза 3: SMOTE (k=7)\n",
            "Accuracy:  0.8243\n",
            "Precision: 0.5684\n",
            "Recall:    0.7670\n",
            "F1-Score:  0.6529\n",
            "ROC-AUC:   0.8735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по Гипотезе 3:**\n",
        "\n",
        "SMOTE помог Recall, но испортил остальное.\n",
        "\n",
        "Гипотеза 3 не подтверждена, соответсвенно игнорируется."
      ],
      "metadata": {
        "id": "9BxA2D1yDSQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# гипотеза 4: новые признаки\n",
        "\n",
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Удаляем выбросы\n",
        "df = df[(df['person_age'] < 100) & (df['person_emp_length'] < 100)]\n",
        "\n",
        "# Заполняем пропуски только в числовых колонках\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# Создаём новые признаки до One-hot encoding\n",
        "df['income_to_loan'] = df['person_income'] / (df['loan_amnt'] + 1)  # +1 чтобы избежать деления на 0\n",
        "df['age_emp_ratio'] = (df['person_age'] + 1) / (df['person_emp_length'] + 1)  # +1 для безопасности\n",
        "\n",
        "print(f\"Новые признаки созданы:\")\n",
        "print(f\"  - income_to_loan: min={df['income_to_loan'].min():.2f}, max={df['income_to_loan'].max():.2f}\")\n",
        "print(f\"  - age_emp_ratio: min={df['age_emp_ratio'].min():.2f}, max={df['age_emp_ratio'].max():.2f}\")\n",
        "\n",
        "# One-hot encoding для категориальных признаков\n",
        "df = pd.get_dummies(df, columns=['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'], drop_first=False)\n",
        "\n",
        "# Разделяем на признаки и целевой класс\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "print(f\"\\nКоличество признаков (без новых): 26\")\n",
        "print(f\"Количество признаков (с новыми): {X.shape[1]}\")\n",
        "\n",
        "# Train/test разделение\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Нормализуем данные\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Обучаем KNN с k=7\n",
        "knn_fe = KNeighborsClassifier(n_neighbors=7)\n",
        "knn_fe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn_fe.predict(X_test)\n",
        "y_pred_proba = knn_fe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"гипотеза 4: новые признаки(k=7)\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score:  {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_proba):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbLk2rnpD0q5",
        "outputId": "10d21607-f32d-48b5-96c9-ac09cd56302a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Новые признаки созданы:\n",
            "  - income_to_loan: min=1.20, max=1265.82\n",
            "  - age_emp_ratio: min=1.38, max=74.00\n",
            "\n",
            "Количество признаков (без новых): 26\n",
            "Количество признаков (с новыми): 28\n",
            "гипотеза 4: новые признаки(k=7)\n",
            "Accuracy:  0.8988\n",
            "Precision: 0.8943\n",
            "Recall:    0.6015\n",
            "F1-Score:  0.7192\n",
            "ROC-AUC:   0.8680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 4:**\n",
        "\n",
        "Новые признаки особо не улучшили качество, только Precision чутка вырос.\n",
        "\n",
        "\n",
        "Гипотеза 4 не подтверждена, игнорируется."
      ],
      "metadata": {
        "id": "nXRH2lgBEFDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c., d. и e. Формирование, обучение и оценка качества улучшенного бейзлайна**\n"
      ],
      "metadata": {
        "id": "KFuDrJrUFKiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Улучшенный бейзлайн\n",
        "# гипотеза 1 (Препроцессинг) + гипотеза 2 (k=7)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Улучшение 1: Удаляем выбросы\n",
        "df = df[(df['person_age'] < 100) & (df['person_emp_length'] < 100)]\n",
        "\n",
        "# Улучшение 2: Заполняем пропуски\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# Улучшение 3: One-hot encoding\n",
        "df = pd.get_dummies(df, columns=['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'], drop_first=False)\n",
        "\n",
        "# Разделяем на признаки и целевой класс\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "# Train/test разделение\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Нормализуем данные\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Улучшение 4: k=7 (вместо k=5)\n",
        "knn_improved = KNeighborsClassifier(n_neighbors=7)\n",
        "knn_improved.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания\n",
        "y_pred = knn_improved.predict(X_test)\n",
        "y_pred_proba = knn_improved.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Метрики\n",
        "print(\"Улучшенный бейзлайн KNN\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score:  {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_proba):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyLAUUrgFQI9",
        "outputId": "2f3ed319-f110-40c4-ab49-17c44623c18b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Улучшенный бейзлайн KNN\n",
            "Accuracy:  0.9020\n",
            "Precision: 0.8851\n",
            "Recall:    0.6264\n",
            "F1-Score:  0.7336\n",
            "ROC-AUC:   0.8742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f. Сравнение резульатов с пунктом 2**\n",
        "\n",
        "Базовый KNN:\n",
        "\n",
        "Accuracy: 0.8716\n",
        "\n",
        "Precision: 0.7882\n",
        "\n",
        "Recall: 0.5626\n",
        "\n",
        "F1-Score: 0.6565\n",
        "\n",
        "ROC-AUC: 0.8438\n",
        "\n",
        "Улучшенный KNN:\n",
        "\n",
        "Accuracy: 0.9020\n",
        "\n",
        "Precision: 0.8851\n",
        "\n",
        "Recall: 0.6264\n",
        "\n",
        "F1-Score: 0.7336\n",
        "\n",
        "ROC-AUC: 0.8742\n",
        "\n",
        "Все метрики выросли, что показывает явное улучшение модели. Accuracy увеличилась на 3%, Precision стал выше почти на 10%, Recall подрос с 56% до 62%, а F1-Score улучшился на 8%. Это произошло благодаря улучшенному препроцессингу (удаление выбросов и One-hot encoding) и подбору оптимального k=7 вместо дефолтных k=5.​"
      ],
      "metadata": {
        "id": "4EAL7OAaO9Fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**g. Выводы**\n",
        "\n",
        "Удалось значительно улучшить качество модели по сравнению с базовым бейзлайном. Основной вклад внесли две подтвержденные гипотезы: улучшенный препроцессинг данных (удаление выбросов и переход на One-hot encoding) и подбор оптимального гиперпараметра k=7 через кросс-валидацию. Гипотеза с SMOTE не сработала, потому что хоть Recall и вырос, остальные метрики сильно просели, поэтому её отбросил. Добавление новых признаков тоже особо не помогло. В итоге получил рабочую модель с хорошим балансом между precision и recall."
      ],
      "metadata": {
        "id": "bkI2LmU4PDtT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Имплементация алгоритма машинного обучения"
      ],
      "metadata": {
        "id": "A6TFvcsaSEnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Имплементация KNN**"
      ],
      "metadata": {
        "id": "RxkoabshGCIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Имплементация KNN\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class KNNClassifier:\n",
        "\n",
        "    def __init__(self, k=7):\n",
        "        \"\"\"\n",
        "        k: количество соседей для рассмотрения\n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Сохраняем тренировочные данные\n",
        "        \"\"\"\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def euclidean_distance(self, x1, x2):\n",
        "        \"\"\"\n",
        "        Вычисляем евклидово расстояние между двумя точками\n",
        "        \"\"\"\n",
        "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "\n",
        "    def predict_single(self, x):\n",
        "        \"\"\"\n",
        "        Предсказываем класс для одной точки\n",
        "        \"\"\"\n",
        "        # Вычисляем расстояния до всех тренировочных точек\n",
        "        distances = []\n",
        "        for x_train in self.X_train:\n",
        "            dist = self.euclidean_distance(x, x_train)\n",
        "            distances.append(dist)\n",
        "\n",
        "        # Находим индексы k ближайших соседей\n",
        "        distances = np.array(distances)\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "\n",
        "        # Берём классы k ближайших соседей\n",
        "        k_nearest_labels = self.y_train[k_indices]\n",
        "\n",
        "        # Возвращаем самый частый класс\n",
        "        most_common = Counter(k_nearest_labels).most_common(1)\n",
        "        return most_common[0][0]\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"\n",
        "        Предсказываем классы для всех тестовых точек\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            pred = self.predict_single(x)\n",
        "            predictions.append(pred)\n",
        "        return np.array(predictions)"
      ],
      "metadata": {
        "id": "enoyL0fiGItf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Обучение имплементированной модели с базовым бейзлайном**"
      ],
      "metadata": {
        "id": "WOnLF3CzNxW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_base = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Label Encoding\n",
        "for col in ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']:\n",
        "    le = LabelEncoder()\n",
        "    df_base[col] = le.fit_transform(df_base[col])\n",
        "\n",
        "# Заполняем пропуски\n",
        "df_base = df_base.fillna(df_base.median())\n",
        "\n",
        "# Разделяем\n",
        "X_base = df_base.drop('loan_status', axis=1)\n",
        "y_base = df_base['loan_status']\n",
        "\n",
        "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X_base, y_base, test_size=0.2, random_state=42, stratify=y_base)\n",
        "\n",
        "# Нормализуем\n",
        "scaler_base = StandardScaler()\n",
        "X_train_base = scaler_base.fit_transform(X_train_base)\n",
        "X_test_base = scaler_base.transform(X_test_base)\n",
        "\n",
        "# Конвертируем в numpy\n",
        "X_train_base = np.array(X_train_base)\n",
        "X_test_base = np.array(X_test_base)\n",
        "y_train_base = np.array(y_train_base)\n",
        "y_test_base = np.array(y_test_base)\n",
        "\n",
        "# Используем KNNClassifier\n",
        "knn_base = KNNClassifier(k=5)\n",
        "knn_base.fit(X_train_base, y_train_base)\n",
        "\n",
        "print(\"KNN без улучшений обучен\")\n",
        "\n",
        "y_pred_base = knn_base.predict(X_test_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq230dZJN5by",
        "outputId": "dad3e79c-63ae-4e69-fa55-d855186aec39"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN без улучшений обучен\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c. Оценка качества имплементированной модели с базовым бейзлайном**"
      ],
      "metadata": {
        "id": "1mX-DH-aTFBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вычисляем вероятности для ROC-AUC\n",
        "y_pred_proba_base = []\n",
        "for i, x_test in enumerate(X_test_base):\n",
        "    distances = np.sqrt(np.sum((X_train_base - x_test) ** 2, axis=1))\n",
        "    k_indices = np.argsort(distances)[:5]\n",
        "    k_nearest_labels = y_train_base[k_indices]\n",
        "    prob_class_1 = np.sum(k_nearest_labels) / 5\n",
        "    y_pred_proba_base.append(prob_class_1)\n",
        "    if (i + 1) % 500 == 0:\n",
        "        print(f\"Обработано {i + 1}/{len(X_test_base)}\")\n",
        "\n",
        "y_pred_proba_base = np.array(y_pred_proba_base)\n",
        "\n",
        "print(\"Имплементированный KNN без улучшений (k=5)\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_test_base, y_pred_base):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_base, y_pred_base):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test_base, y_pred_base):.4f}\")\n",
        "print(f\"F1-Score:  {f1_score(y_test_base, y_pred_base):.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_score(y_test_base, y_pred_proba_base):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNPA44T8Ui-W",
        "outputId": "facad1b1-6721-46f9-e0f6-b5abcc90c5ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обработано 500/6517\n",
            "Обработано 1000/6517\n",
            "Обработано 1500/6517\n",
            "Обработано 2000/6517\n",
            "Обработано 2500/6517\n",
            "Обработано 3000/6517\n",
            "Обработано 3500/6517\n",
            "Обработано 4000/6517\n",
            "Обработано 4500/6517\n",
            "Обработано 5000/6517\n",
            "Обработано 5500/6517\n",
            "Обработано 6000/6517\n",
            "Обработано 6500/6517\n",
            "Имплементированный KNN без улучшений (k=5)\n",
            "Accuracy:  0.8716\n",
            "Precision: 0.7882\n",
            "Recall:    0.5626\n",
            "F1-Score:  0.6565\n",
            "ROC-AUC:   0.8438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d. Сравнение результатов с пунктом 2**\n",
        "\n",
        "Результаты полностью совпали, имплементированный KNN дает точно такие же зачения метрик, как и sklearn.\n",
        "- Accuracy:  0.8716\n",
        "- Precision: 0.7882\n",
        "- Recall:    0.5626\n",
        "- F1-Score:  0.6565\n",
        "- ROC-AUC:   0.8438"
      ],
      "metadata": {
        "id": "ihtieKvCTWb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e. Выводы**\n",
        "\n",
        "Результаты сошлись со вторым пунктом, это говорит о правильности, но время выполнения было заметно больше, чем в случае sklearn."
      ],
      "metadata": {
        "id": "Gm1w_muuTmEb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f. и g. Добавление техник из улучшенного бейзлайна и обучение**"
      ],
      "metadata": {
        "id": "Z9Mg7pOsQQSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Имплементация с улучшеннным бейзлайном\n",
        "\n",
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Удаляем выбросы\n",
        "df = df[(df['person_age'] < 100) & (df['person_emp_length'] < 100)]\n",
        "\n",
        "# Заполняем пропуски\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# One-hot encoding\n",
        "df = pd.get_dummies(df, columns=['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'], drop_first=False)\n",
        "\n",
        "# Разделяем\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "# Train/test разделение\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Нормализуем\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# конвертируем в numpy\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Обучаем\n",
        "knn_custom = KNNClassifier(k=7)\n",
        "knn_custom.fit(X_train, y_train)\n",
        "\n",
        "print(\"KNN обучен\")\n",
        "\n",
        "# Предсказания\n",
        "y_pred_custom = knn_custom.predict(X_test)\n",
        "\n",
        "print(f\"Размер тестового набора: {len(X_test)}\")\n",
        "print(f\"Первые 10 предсказаний: {y_pred_custom[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADSbrKfjGRQT",
        "outputId": "e1aaaa8c-e3bd-47db-e847-1c584d219ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN обучен\n",
            "Размер тестового набора: 6336\n",
            "Первые 10 предсказаний: [0 0 0 0 0 0 0 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**h. Оценка качества имплементированной модели с улучшенным бейзлайном**\n",
        "\n"
      ],
      "metadata": {
        "id": "4ffV2OKbMDoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba_custom = []\n",
        "for i, x_test in enumerate(X_test):\n",
        "    distances = np.sqrt(np.sum((X_train - x_test) ** 2, axis=1))\n",
        "    k_indices = np.argsort(distances)[:7]\n",
        "    k_nearest_labels = y_train[k_indices]\n",
        "    prob_class_1 = np.sum(k_nearest_labels) / 7  # Доля класса 1 среди соседей\n",
        "    y_pred_proba_custom.append(prob_class_1)\n",
        "    if (i + 1) % 500 == 0:\n",
        "        print(f\"Обработано {i + 1}/{len(X_test)}\")\n",
        "\n",
        "y_pred_proba_custom = np.array(y_pred_proba_custom)\n",
        "\n",
        "print(\"имплементированный KNN (k=7) с улучшениями\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_custom):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_custom):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test, y_pred_custom):.4f}\")\n",
        "print(f\"F1-Score:  {f1_score(y_test, y_pred_custom):.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_proba_custom):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNyGNkHUMIbt",
        "outputId": "8e557b79-3169-437f-8e2d-61d223956e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обработано 500/6336\n",
            "Обработано 1000/6336\n",
            "Обработано 1500/6336\n",
            "Обработано 2000/6336\n",
            "Обработано 2500/6336\n",
            "Обработано 3000/6336\n",
            "Обработано 3500/6336\n",
            "Обработано 4000/6336\n",
            "Обработано 4500/6336\n",
            "Обработано 5000/6336\n",
            "Обработано 5500/6336\n",
            "Обработано 6000/6336\n",
            "имплементированный KNN (k=7) с улучшениями\n",
            "Accuracy:  0.9020\n",
            "Precision: 0.8851\n",
            "Recall:    0.6264\n",
            "F1-Score:  0.7336\n",
            "ROC-AUC:   0.8742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**i. Сравнение с результатами из пункта 3**\n",
        "\n",
        "Результаты полностью сошлись с третьим пунктом\n",
        "- Accuracy:  0.9020\n",
        "- Precision: 0.8851\n",
        "- Recall:    0.6264\n",
        "- F1-Score:  0.7336\n",
        "- ROC-AUC:   0.8742"
      ],
      "metadata": {
        "id": "uSv3zLPYTyk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**j. Выводы**\n",
        "\n",
        "Понадобилось намного больше времени на ожидание результатов по сравнению с KNN sklearn, но тем не менее цифры получились те же."
      ],
      "metadata": {
        "id": "3O8R5-0CT7UJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Регрессия"
      ],
      "metadata": {
        "id": "TtdUL-YDzfNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Выбор начальных условий"
      ],
      "metadata": {
        "id": "dE_tTqIQR6Vn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Выбор набора данных**\n",
        "\n",
        "Я выбрал датасет **India Job Market & Salary Trends**, потому что на его основе можно предсказывать зарплаты по таким параметрам, как должность, опыт, город, компания, формат работы и уровень спроса. Можно понять, какие зарплаты получают разные IT-специалисты в разных городах, а компаниям оценить конкуренцию и уровень рынка.\n"
      ],
      "metadata": {
        "id": "QzeP7YlPSBvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c. Выбор метрик и их обоснование**\n",
        "\n",
        "- MAE (Mean Absolute Error)\n",
        "Средняя ошибка в рупиях. Если MAE = 50000, значит модель в среднем промахивается на 50 тысяч рупий.\n",
        "\n",
        "- RMSE (Root Mean Squared Error)\n",
        "Тоже средняя ошибка в рупиях, но сильнее штрафует большие промахи. Если модель иногда ошибается на миллион рупий, RMSE это покажет лучше чем MAE\n",
        "\n",
        "- R² (коэффициент детерминации)\n",
        "Показывает, насколько хорошо модель объясняет данные. Значение от 0 до 1, чем ближе к 1, тем лучше\n",
        "\n",
        "- MAPE (Mean Absolute Percentage Error)\n",
        "Средняя ошибка в процентах. Если MAPE = 10%, значит модель в среднем промахивается на 10% от реальной зарплаты. Удобно для сравнения точности на разных уровнях зарплат\n",
        "\n",
        "Эти метрики смотрят на качество модели с разных сторон: абсолютные ошибки в деньгах, общее качество предсказания и относительная точность. Вместе они дают полную картину того, как работает модель на данных о зарплатах."
      ],
      "metadata": {
        "id": "5jQcHrbjeSop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Создание бейзлайна и оценка качества"
      ],
      "metadata": {
        "id": "ibfoXV6nfY0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Обучение модели sklearn**"
      ],
      "metadata": {
        "id": "iCyRacB-gq1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "\n",
        "\n",
        "# Убираем ненужные колонки\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "\n",
        "# Кодируем категориальные признаки\n",
        "for col in ['Company_Name', 'Job_Role', 'Experience_Level', 'City']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "\n",
        "# Заполняем пропуски медианой\n",
        "df = df.fillna(df.median())\n",
        "\n",
        "\n",
        "# Разделяем на признаки и целевую переменную\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "\n",
        "# Train/test разделение\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Нормализуем данные\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Обучение\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Предсказания\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "\n",
        "# Вычисляем метрики\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "\n",
        "# Вывод метрик\n",
        "print(\"KNN (k=5) Бейзлайн\")\n",
        "print(f\"MAE:   {mae:.2f}\")\n",
        "print(f\"RMSE:  {rmse:.2f}\")\n",
        "print(f\"R²:    {r2:.4f}\")\n",
        "print(f\"MAPE:  {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOg_E96tg5mS",
        "outputId": "100976b0-8f4c-4ebe-9dff-97f7c49342fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN (k=5) Бейзлайн\n",
            "MAE:   580637.80\n",
            "RMSE:  769368.94\n",
            "R²:    0.0597\n",
            "MAPE:  58.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Оценка качества модели**\n",
        "\n",
        "Модель показывает слабоватые результаты на базовом бейзлайне. R² равен всего 0.0597, то есть модель объясняет только 6% разброса зарплат, что очень мало. MAPE составляет 58%, то есть в среднем модель ошибается больше чем на половину реальной зарплаты. MAE около 580 тысяч рупий и RMSE около 769 тысяч показывают большую абсолютную ошибку в предсказаниях. Такое низкое качество я могу объяснить тем, что это базовый бейзлайн без препроцессинга: используется простой Label Encoding для категориальных признаков, не удалены выбросы, не подобраны гиперпараметры."
      ],
      "metadata": {
        "id": "P88jUtLmUs-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Улучшение бейзлайна"
      ],
      "metadata": {
        "id": "ZW_lL9gNVLn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Формулировка гипотез**\n",
        "\n",
        "**Гипотеза 1: Препроцессинг**\n",
        "\n",
        "Удалить выбросы в зарплатах (слишком высокие или низкие значения искажают модель)\n",
        "\n",
        "Использовать One-hot encoding вместо Label Encoding для категориальных признаков (Company_Name, Job_Role, City, Experience_Level)\n",
        "\n",
        "**Гипотеза 2: Подбор гиперпараметров**\n",
        "\n",
        "Найти оптимальное k (вместо k=5) с помощью кросс-валидации\n",
        "\n",
        "Проверить разные значения k от 3 до 30\n",
        "\n",
        "**Гипотеза 3: Новые признаки**\n",
        "\n",
        "Создать новый признаки: среднюю зарплату по городу, среднюю зарплату по должности, соотношение Demand_Index к Remote_Option_Flag\n",
        "\n",
        "**Гипотеза 4: Масштабирование целевой переменной**\n",
        "\n",
        "Попробовать логарифмирование зарплаты для уменьшения разброса значений\n",
        "\n",
        "Проверить, улучшит ли это способность модели предсказывать на разных уровнях зарплат"
      ],
      "metadata": {
        "id": "OQ2GFRZKV5JF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Проверка гипотез**"
      ],
      "metadata": {
        "id": "zcWqRs247tvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 1: препроцессинг (удаление выбросов + One-hot encoding)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "\n",
        "\n",
        "# Убираем ненужные колонки\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "\n",
        "# Удаляем выбросы в зарплате\n",
        "print(\"До удаления выбросов:\", len(df))\n",
        "q1 = df['Salary_INR'].quantile(0.01)\n",
        "q99 = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q1) & (df['Salary_INR'] <= q99)]\n",
        "print(\"После удаления выбросов:\", len(df))\n",
        "\n",
        "\n",
        "# Заполняем пропуски только в числовых колонках\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "\n",
        "# One-hot encoding для категориальных признаков\n",
        "df = pd.get_dummies(df, columns=['Company_Name', 'Job_Role', 'Experience_Level', 'City'], drop_first=False)\n",
        "\n",
        "\n",
        "# Разделяем на признаки и целевую переменную\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "\n",
        "print(f\"Количество признаков после One-hot: {X.shape[1]}\")\n",
        "\n",
        "\n",
        "# Train/test разделение\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Нормализуем данные\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Обучаем KNN с k=5\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Предсказания\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "\n",
        "# Вычисляем метрики\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "\n",
        "# Метрики\n",
        "print(\"Гипотеза 1: препроцессинг\")\n",
        "print(f\"MAE:   {mae:.2f}\")\n",
        "print(f\"RMSE:  {rmse:.2f}\")\n",
        "print(f\"R²:    {r2:.4f}\")\n",
        "print(f\"MAPE:  {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjZZnwA5W1QV",
        "outputId": "c999db29-926d-40fd-a5fd-05312d048bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "До удаления выбросов: 30000\n",
            "После удаления выбросов: 29400\n",
            "Количество признаков после One-hot: 66\n",
            "Гипотеза 1: препроцессинг\n",
            "MAE:   416551.74\n",
            "RMSE:  537939.58\n",
            "R²:    0.4488\n",
            "MAPE:  41.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 1:**\n",
        "\n",
        "R² вырос с 6% до 45%, то есть модель теперь объясняет почти половину разброса зарплат. MAPE снизился с 58% до 41%, ошибки стали меньше. Удаление выбросов и One-hot encoding значительно улучшили качество.\n",
        "\n",
        "Гипотеза 1 подтверждена, используем."
      ],
      "metadata": {
        "id": "yf3_qD6TYIgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 2: подбор гиперпараметров (оптимальное k)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "# Проверяем разные значения k\n",
        "k_values = [3, 5, 7, 9, 11, 15, 20, 25, 30]\n",
        "results = []\n",
        "\n",
        "\n",
        "print(\"Проверка разных значений k с кросс-валидацией (5-fold):\")\n",
        "\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsRegressor(n_neighbors=k)\n",
        "    # Кросс-валидация по R²\n",
        "    cv_scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='r2')\n",
        "    mean_score = cv_scores.mean()\n",
        "    results.append({'k': k, 'mean_r2': mean_score})\n",
        "    print(f\"k={k:2d}: R² (5-fold CV) = {mean_score:.4f}\")\n",
        "\n",
        "\n",
        "# Находим лучшее k\n",
        "best_k = max(results, key=lambda x: x['mean_r2'])['k']\n",
        "best_r2_cv = max(results, key=lambda x: x['mean_r2'])['mean_r2']\n",
        "\n",
        "\n",
        "print(f\"\\nЛучшее k = {best_k} (R² = {best_r2_cv:.4f})\")\n",
        "\n",
        "\n",
        "# Обучаем KNN с лучшим k\n",
        "knn_best = KNeighborsRegressor(n_neighbors=best_k)\n",
        "knn_best.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = knn_best.predict(X_test)\n",
        "\n",
        "\n",
        "# Вычисляем метрики\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "\n",
        "print(f\"Гипотеза 2: подбор k (k={best_k})\")\n",
        "print(f\"MAE:   {mae:.2f}\")\n",
        "print(f\"RMSE:  {rmse:.2f}\")\n",
        "print(f\"R²:    {r2:.4f}\")\n",
        "print(f\"MAPE:  {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09Qzqgh6YP3O",
        "outputId": "a49e2b35-3e3c-4bc6-9fb0-ad4276bb2d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Проверка разных значений k с кросс-валидацией (5-fold):\n",
            "k= 3: R² (5-fold CV) = 0.3989\n",
            "k= 5: R² (5-fold CV) = 0.4564\n",
            "k= 7: R² (5-fold CV) = 0.4769\n",
            "k= 9: R² (5-fold CV) = 0.4833\n",
            "k=11: R² (5-fold CV) = 0.4851\n",
            "k=15: R² (5-fold CV) = 0.4861\n",
            "k=20: R² (5-fold CV) = 0.4889\n",
            "k=25: R² (5-fold CV) = 0.4911\n",
            "k=30: R² (5-fold CV) = 0.4930\n",
            "\n",
            "Лучшее k = 30 (R² = 0.4930)\n",
            "Гипотеза 2: подбор k (k=30)\n",
            "MAE:   407087.34\n",
            "RMSE:  516451.79\n",
            "R²:    0.4919\n",
            "MAPE:  41.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 2:**\n",
        "\n",
        "R² вырос с 45% до 49%, модель стала лучше объяснять разброс зарплат. MAE и RMSE снизились, значит ошибки меньше. MAPE чуть вырос, но это некритично. Кросс-валидация подтвердила, что k=30 оптимальнее чем k=5.\n",
        "\n",
        "Гипотеза 2 подтвердилась, используем"
      ],
      "metadata": {
        "id": "mgOFYJz5Y3So"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 3: Новые признаки\n",
        "\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "\n",
        "# Удаляем выбросы\n",
        "q1 = df['Salary_INR'].quantile(0.01)\n",
        "q99 = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q1) & (df['Salary_INR'] <= q99)]\n",
        "\n",
        "\n",
        "# Заполняем пропуски\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "\n",
        "# Создаем новые признаки до One-hot encoding\n",
        "df['avg_salary_by_city'] = df.groupby('City')['Salary_INR'].transform('mean')\n",
        "df['avg_salary_by_role'] = df.groupby('Job_Role')['Salary_INR'].transform('mean')\n",
        "df['demand_remote_ratio'] = df['Demand_Index'] / (df['Remote_Option_Flag'] + 1)\n",
        "\n",
        "\n",
        "print(f\"Новые признаки созданы:\")\n",
        "print(f\"  - avg_salary_by_city\")\n",
        "print(f\"  - avg_salary_by_role\")\n",
        "print(f\"  - demand_remote_ratio\")\n",
        "\n",
        "\n",
        "# One-hot encoding\n",
        "df = pd.get_dummies(df, columns=['Company_Name', 'Job_Role', 'Experience_Level', 'City'], drop_first=False)\n",
        "\n",
        "\n",
        "# Разделяем\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "\n",
        "print(f\"\\nКоличество признаков (без новых): 66\")\n",
        "print(f\"Количество признаков (с новыми): {X.shape[1]}\")\n",
        "\n",
        "\n",
        "# Train/test разделение\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Нормализуем данные\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Обучаем KNN с k=30\n",
        "knn_fe = KNeighborsRegressor(n_neighbors=30)\n",
        "knn_fe.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = knn_fe.predict(X_test)\n",
        "\n",
        "\n",
        "# Метрики\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "\n",
        "print(\"Гипотеза 3: Новые признаки (k=30)\")\n",
        "print(f\"MAE:   {mae:.2f}\")\n",
        "print(f\"RMSE:  {rmse:.2f}\")\n",
        "print(f\"R²:    {r2:.4f}\")\n",
        "print(f\"MAPE:  {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJR9jozSY4bZ",
        "outputId": "368f957f-e46e-4c17-d80f-7b4d8b3b4ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Новые признаки созданы:\n",
            "  - avg_salary_by_city\n",
            "  - avg_salary_by_role\n",
            "  - demand_remote_ratio\n",
            "\n",
            "Количество признаков (без новых): 66\n",
            "Количество признаков (с новыми): 69\n",
            "Гипотеза 3: Новые признаки (k=30)\n",
            "MAE:   402005.45\n",
            "RMSE:  506240.34\n",
            "R²:    0.5118\n",
            "MAPE:  40.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 3:**\n",
        "\n",
        "R² вырос с 49% до 51%, модель теперь объясняет больше половины разброса зарплат. Все ошибки снизились.\n",
        "\n",
        "Гипотеза 3 подтверждена, используем."
      ],
      "metadata": {
        "id": "WskejUy7ZgNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 4: масштабирование целевой переменной\n",
        "\n",
        "\n",
        "# Загружаем данные заново\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "\n",
        "# Удаляем выбросы\n",
        "q1 = df['Salary_INR'].quantile(0.01)\n",
        "q99 = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q1) & (df['Salary_INR'] <= q99)]\n",
        "\n",
        "\n",
        "# Заполняем пропуски\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "\n",
        "# Логарифмируем целевую переменную\n",
        "df['Salary_INR_log'] = np.log1p(df['Salary_INR'])\n",
        "\n",
        "\n",
        "print(\"Масштабирование целевой переменной:\")\n",
        "print(f\"  До: min={df['Salary_INR'].min():.0f}, max={df['Salary_INR'].max():.0f}\")\n",
        "print(f\"  После log: min={df['Salary_INR_log'].min():.2f}, max={df['Salary_INR_log'].max():.2f}\")\n",
        "\n",
        "\n",
        "# One-hot encoding\n",
        "df_encoded = pd.get_dummies(df, columns=['Company_Name', 'Job_Role', 'Experience_Level', 'City'], drop_first=False)\n",
        "\n",
        "\n",
        "# Разделяем (используем логарифмированную зарплату)\n",
        "X = df_encoded.drop(['Salary_INR', 'Salary_INR_log'], axis=1)\n",
        "y_log = df_encoded['Salary_INR_log']\n",
        "y_original = df_encoded['Salary_INR']\n",
        "\n",
        "\n",
        "# Train/test разделение\n",
        "X_train, X_test, y_train_log, y_test_log, y_train_orig, y_test_orig = train_test_split(\n",
        "    X, y_log, y_original, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Нормализуем данные\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Обучаем KNN с k=30 на логарифмированных данных\n",
        "knn_log = KNeighborsRegressor(n_neighbors=30)\n",
        "knn_log.fit(X_train, y_train_log)\n",
        "\n",
        "\n",
        "# Предсказания в логарифмической шкале\n",
        "y_pred_log = knn_log.predict(X_test)\n",
        "\n",
        "\n",
        "# Обратное преобразование в исходную шкалу\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "\n",
        "\n",
        "# Метрики на исходной шкале\n",
        "mae = mean_absolute_error(y_test_orig, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
        "r2 = r2_score(y_test_orig, y_pred)\n",
        "mape = np.mean(np.abs((y_test_orig - y_pred) / y_test_orig)) * 100\n",
        "\n",
        "\n",
        "print(\"\\nГипотеза 4: логарифмирование целевой переменной (k=30)\")\n",
        "print(f\"MAE:   {mae:.2f}\")\n",
        "print(f\"RMSE:  {rmse:.2f}\")\n",
        "print(f\"R²:    {r2:.4f}\")\n",
        "print(f\"MAPE:  {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G_l57BVZ9OO",
        "outputId": "dc4604b2-c133-4b52-b1bf-adff776391af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Масштабирование целевой переменной:\n",
            "  До: min=338096, max=3974203\n",
            "  После log: min=12.73, max=15.20\n",
            "\n",
            "Гипотеза 4: логарифмирование целевой переменной (k=30)\n",
            "MAE:   413992.04\n",
            "RMSE:  542083.63\n",
            "R²:    0.4403\n",
            "MAPE:  37.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 4:**\n",
        "\n",
        "R² упал с 49% до 44%, MAE и RMSE выросли. MAPE немного улучшился, но это не компенсирует ухудшение остальных метрик. Логарифмирование не помогло для этого датасета.\n",
        "\n",
        "Гипотеза 4 не подтверждена, не используем."
      ],
      "metadata": {
        "id": "0cwZXDvKaLqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c. и d. Формирование улучшенного бейзлайна и обучение модели**"
      ],
      "metadata": {
        "id": "FB0ZWpzy_kSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 1 (Препроцессинг) + гипотеза 2 (k=30) + гипотеза 3 (новые признаки)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "\n",
        "# Улучшение 1: Удаляем выбросы\n",
        "q1 = df['Salary_INR'].quantile(0.01)\n",
        "q99 = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q1) & (df['Salary_INR'] <= q99)]\n",
        "\n",
        "\n",
        "# Улучшение 2: Заполняем пропуски\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "\n",
        "# Улучшение 3: Создаем новые признаки\n",
        "df['avg_salary_by_city'] = df.groupby('City')['Salary_INR'].transform('mean')\n",
        "df['avg_salary_by_role'] = df.groupby('Job_Role')['Salary_INR'].transform('mean')\n",
        "df['demand_remote_ratio'] = df['Demand_Index'] / (df['Remote_Option_Flag'] + 1)\n",
        "\n",
        "\n",
        "# Улучшение 4: One-hot encoding\n",
        "df = pd.get_dummies(df, columns=['Company_Name', 'Job_Role', 'Experience_Level', 'City'], drop_first=False)\n",
        "\n",
        "\n",
        "# Разделяем на признаки и целевую переменную\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "\n",
        "# Train/test разделение\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Нормализуем данные\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Улучшение 5: k=30 (вместо k=5)\n",
        "knn_improved = KNeighborsRegressor(n_neighbors=30)\n",
        "knn_improved.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Предсказания\n",
        "y_pred = knn_improved.predict(X_test)\n",
        "\n",
        "\n",
        "# Метрики\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "\n",
        "print(\"Улучшенный бейзлайн KNN\")\n",
        "print(f\"MAE:   {mae:.2f}\")\n",
        "print(f\"RMSE:  {rmse:.2f}\")\n",
        "print(f\"R²:    {r2:.4f}\")\n",
        "print(f\"MAPE:  {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krZ4cGUVatZM",
        "outputId": "f9f62516-5975-4b46-d089-d7659c165f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Улучшенный бейзлайн KNN\n",
            "MAE:   402005.45\n",
            "RMSE:  506240.34\n",
            "R²:    0.5118\n",
            "MAPE:  40.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f. Сравнение результатов с пунктом 2**\n",
        "\n",
        "**Обычный бейзлайн:**\n",
        "\n",
        "MAE  = 580637.80\n",
        "\n",
        "RMSE = 769368.94\n",
        "\n",
        "R²   = 0.0597\n",
        "\n",
        "MAPE = 58.33%\n",
        "\n",
        "\n",
        "\n",
        "**Улучшенный бейзлайн:**\n",
        "\n",
        "MAE  = 402005.45\n",
        "\n",
        "RMSE = 506240.34\n",
        "\n",
        "R²   = 0.5118\n",
        "\n",
        "MAPE = 40.47%\n",
        "\n",
        "Видно, что после улучшений модель стала гораздо лучше объяснять данные (R² с 6% до 51%) и заметно снизила как абсолютные, так и относительные ошибки в предсказании зарплат."
      ],
      "metadata": {
        "id": "TCfhgdOS-E0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**g. Выводы**\n",
        "\n",
        "Все метрики значительно улучшились. R² вырос с 6% до 51%, то есть модель теперь объясняет больше половины разброса зарплат вместо почти ничего. MAE снизилась на 178 тысяч рупий, MAPE упал с 58% до 40%. Улучшения достигнуты за счет удаления выбросов, One-hot encoding, создания новых признаков и подбора оптимального k=30."
      ],
      "metadata": {
        "id": "-FLCXgMXjWlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Имплементация алгоритма машинного обучения"
      ],
      "metadata": {
        "id": "zx4MGdXsdElO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Имплементация**"
      ],
      "metadata": {
        "id": "gN5U2V-xeM_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "class KNNRegressor:\n",
        "\n",
        "    def __init__(self, k=5):\n",
        "        \"\"\"\n",
        "        k: количество соседей для рассмотрения\n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Сохраняем тренировочные данные\n",
        "        \"\"\"\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def euclidean_distance(self, x1, x2):\n",
        "        \"\"\"\n",
        "        Вычисляем евклидово расстояние между двумя точками\n",
        "        \"\"\"\n",
        "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "\n",
        "    def predict_single(self, x):\n",
        "        \"\"\"\n",
        "        Предсказываем значение для одной точки\n",
        "        \"\"\"\n",
        "        # Вычисляем расстояния до всех тренировочных точек\n",
        "        distances = []\n",
        "        for x_train in self.X_train:\n",
        "            dist = self.euclidean_distance(x, x_train)\n",
        "            distances.append(dist)\n",
        "\n",
        "        # Находим индексы k ближайших соседей\n",
        "        distances = np.array(distances)\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "\n",
        "        # Берём значения k ближайших соседей\n",
        "        k_nearest_values = self.y_train[k_indices]\n",
        "\n",
        "        # Возвращаем среднее значение\n",
        "        return np.mean(k_nearest_values)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"\n",
        "        Предсказываем значения для всех тестовых точек\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            pred = self.predict_single(x)\n",
        "            predictions.append(pred)\n",
        "        return np.array(predictions)\n",
        "\n",
        "\n",
        "print(\"KNN имплементирован\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhCUl_D9dVN-",
        "outputId": "b31d2cee-cef2-4916-c772-8d7fda33b899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN имплементирован\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Обучение имплементированной модели с базовым бейзлайном**"
      ],
      "metadata": {
        "id": "rrHwQBjkd2GV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучаем KNN на данных без улучшений\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "\n",
        "# Label Encoding\n",
        "for col in ['Company_Name', 'Job_Role', 'Experience_Level', 'City']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "\n",
        "# Заполняем пропуски\n",
        "df = df.fillna(df.median())\n",
        "\n",
        "\n",
        "# Разделяем\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Нормализуем\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Конвертируем в numpy\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "# Используем KNNRegressor (k=5)\n",
        "knn_base = KNNRegressor(k=5)\n",
        "knn_base.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"KNN без улучшений обучен\")\n",
        "\n",
        "\n",
        "y_pred_base = knn_base.predict(X_test)\n",
        "\n",
        "\n",
        "print(f\"Размер тестового набора: {len(X_test)}\")\n",
        "print(f\"Первые 10 предсказаний: {y_pred_base[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpaZUzp-dsZc",
        "outputId": "3de0cd8f-bcab-4eb0-808e-82dd614d2265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN без улучшений обучен\n",
            "Размер тестового набора: 6000\n",
            "Первые 10 предсказаний: [1031784.2 1142354.2  654170.2 1761596.4 1412841.   760500.  1623495.6\n",
            "  924672.  1024848.4 1192255.4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c. Оценка качества имплементированной модели с базовым бейзлайном**\n",
        "\n"
      ],
      "metadata": {
        "id": "_iZVUL-0eBUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка качества имплементированного KNN без улучшений\n",
        "\n",
        "\n",
        "# Вычисляем метрики\n",
        "mae = mean_absolute_error(y_test, y_pred_base)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_base))\n",
        "r2 = r2_score(y_test, y_pred_base)\n",
        "mape = np.mean(np.abs((y_test - y_pred_base) / y_test)) * 100\n",
        "\n",
        "\n",
        "print(\"Имплементированный KNN с простым бейзлайном (k=5)\")\n",
        "print(f\"MAE:   {mae:.2f}\")\n",
        "print(f\"RMSE:  {rmse:.2f}\")\n",
        "print(f\"R²:    {r2:.4f}\")\n",
        "print(f\"MAPE:  {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weyDk0lMiutX",
        "outputId": "00818445-d935-4ef6-9866-d3e08f8df154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Имплементированный KNN с простым бейзлайном (k=5)\n",
            "MAE:   580607.22\n",
            "RMSE:  769253.75\n",
            "R²:    0.0600\n",
            "MAPE:  58.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d. Сравнение результатов модели с результатами из пункта 2**\n",
        "\n",
        "**Имплементированный:**\n",
        "\n",
        "MAE:   580607.22\n",
        "\n",
        "RMSE:  769253.75\n",
        "\n",
        "R²:    0.0600\n",
        "\n",
        "MAPE:  58.33%\n",
        "\n",
        "**Sklearn:**\n",
        "\n",
        "MAE:   580637.80\n",
        "\n",
        "RMSE:  769368.94\n",
        "\n",
        "R²:    0.0597\n",
        "\n",
        "MAPE:  58.33%\n",
        "\n",
        "Результаты совпадают на 99%, минимальные различия из-за округлений при вычислениях."
      ],
      "metadata": {
        "id": "grjyWTfWenz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e. Выводы**\n",
        "\n",
        "Имплементированный KNN без улучшений дает результаты, идентичные sklearn KNN на 99.9%. Все метрики совпадают: MAE около 580 тысяч рупий, RMSE около 769 тысяч, R² = 6%, MAPE = 58%. Это доказывает корректность реализации алгоритма, вычисление евклидовых расстояний, поиск k ближайших соседей и усреднение их значений работают правильно."
      ],
      "metadata": {
        "id": "s--0zib4fKvT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f. и g. Добавление техник из улучшенного бейзлайна и обучение модели**"
      ],
      "metadata": {
        "id": "vuwQzHvsgN3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "\n",
        "# Улучшение 1: Удаляем выбросы\n",
        "q1 = df['Salary_INR'].quantile(0.01)\n",
        "q99 = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q1) & (df['Salary_INR'] <= q99)]\n",
        "\n",
        "\n",
        "# Улучшение 2: Заполняем пропуски\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "\n",
        "# Улучшение 3: Создаем новые признаки\n",
        "df['avg_salary_by_city'] = df.groupby('City')['Salary_INR'].transform('mean')\n",
        "df['avg_salary_by_role'] = df.groupby('Job_Role')['Salary_INR'].transform('mean')\n",
        "df['demand_remote_ratio'] = df['Demand_Index'] / (df['Remote_Option_Flag'] + 1)\n",
        "\n",
        "\n",
        "# Улучшение 4: One-hot encoding\n",
        "df = pd.get_dummies(df, columns=['Company_Name', 'Job_Role', 'Experience_Level', 'City'], drop_first=False)\n",
        "\n",
        "\n",
        "# Разделяем\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Нормализуем\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Конвертируем в numpy\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "# Используем KNNRegressor с k=30\n",
        "knn_improved = KNNRegressor(k=30)\n",
        "knn_improved.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"KNN С улучшениями обучен\")\n",
        "\n",
        "\n",
        "y_pred_improved = knn_improved.predict(X_test)\n",
        "\n",
        "\n",
        "print(f\"Размер тестового набора: {len(X_test)}\")\n",
        "print(f\"Первые 10 предсказаний: {y_pred_improved[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH5gvxFSjhHq",
        "outputId": "0c1bc92f-e9c4-4c59-be1f-5c11295c6dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN С улучшениями обучен\n",
            "Размер тестового набора: 5880\n",
            "Первые 10 предсказаний: [ 981578.66666667  856133.46666667 1323841.2         957188.86666667\n",
            " 2248575.96666667 1184405.66666667 2369860.23333333 2211527.7\n",
            "  952631.53333333 1333867.7       ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**h. Оценка качества имплементированного KNN с улучшенным бейзлайном**"
      ],
      "metadata": {
        "id": "3e9N0R8Pgv7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вычисляем метрики\n",
        "mae = mean_absolute_error(y_test, y_pred_improved)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_improved))\n",
        "r2 = r2_score(y_test, y_pred_improved)\n",
        "mape = np.mean(np.abs((y_test - y_pred_improved) / y_test)) * 100\n",
        "\n",
        "\n",
        "print(\"Имплементированный KNN С улучшениями (k=30)\")\n",
        "print(f\"MAE:   {mae:.2f}\")\n",
        "print(f\"RMSE:  {rmse:.2f}\")\n",
        "print(f\"R²:    {r2:.4f}\")\n",
        "print(f\"MAPE:  {mape:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdwqHNXKnxhh",
        "outputId": "f9770e35-fdac-4b20-a3a1-abcfd99dc3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Имплементированный KNN С улучшениями (k=30)\n",
            "MAE:   402012.62\n",
            "RMSE:  506247.17\n",
            "R²:    0.5118\n",
            "MAPE:  40.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**i. Сравнение результатов с пунктом 3**\n",
        "\n",
        "**Имплементированный:**\n",
        "\n",
        "MAE:   402012.62\n",
        "\n",
        "RMSE:  506247.17\n",
        "\n",
        "R²:    0.5118\n",
        "\n",
        "MAPE:  40.47%\n",
        "\n",
        "**Sklearn:**\n",
        "\n",
        "MAE = 402005.45\n",
        "\n",
        "RMSE = 506240.34\n",
        "\n",
        "R² = 0.5118\n",
        "\n",
        "MAPE = 40.47%\n",
        "\n",
        "Результаты почти идентичны."
      ],
      "metadata": {
        "id": "BcLyWTjxg_Mm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "j. **Выводы**\n",
        "\n",
        "Результаты моего KNN полностью совпали с результатами KNN из sklearn с улучшенным бейзлайом. Разница в MAE и RMSE меньше 10 рупий при общей сумме в 400к, то есть это просто округление. Значения R² и MAPE одинаковые. Это показывает, что имплементированный KNN работает правильно."
      ],
      "metadata": {
        "id": "_XhJMwM6hKhW"
      }
    }
  ]
}