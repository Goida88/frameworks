{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Лабораторная работа №2 (Проведение исследований с логистической и линейной регрессией)\n",
        "\n"
      ],
      "metadata": {
        "id": "w7ibSytmLqlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Классификация"
      ],
      "metadata": {
        "id": "PQ4nPsO7igJH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Создание бейзлайна и оценка качества"
      ],
      "metadata": {
        "id": "66jlFUHivzfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Обучение модели sklearn**"
      ],
      "metadata": {
        "id": "KL8HdnYxv6qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Загружаем датасет\n",
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Кодируем категориальные признаки\n",
        "for col in ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Заполняем пропуски медианой по числовым колонкам\n",
        "df = df.fillna(df.median(numeric_only=True))\n",
        "\n",
        "# Разделяем на признаки (X) и целевой класс (y)\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "# Делим данные на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# Масштабируем признаки\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Обучаем\n",
        "log_reg = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    C=1.0,\n",
        "    n_jobs=-1,\n",
        "    solver='lbfgs'\n",
        ")\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Делаем предсказания классов и вероятностей\n",
        "y_pred = log_reg.predict(X_test)\n",
        "y_pred_proba = log_reg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# метрики\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(\"Логистическая регрессия (бейзлайн)\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prj2cFrhwHgr",
        "outputId": "f800e34a-d985-449a-ae69-e5eae1f2c872"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Логистическая регрессия (бейзлайн)\n",
            "Accuracy: 0.8449\n",
            "Precision: 0.7241\n",
            "Recall: 0.4669\n",
            "F1-Score: 0.5678\n",
            "ROC-AUC: 0.8516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Оценка качества бейзлайна**\n",
        "\n",
        "- Accuracy: 0.8449\n",
        "- Precision: 0.7241\n",
        "- Recall: 0.4669\n",
        "- F1-Score: 0.5678\n",
        "- ROC-AUC: 0.8516\n",
        "\n",
        "Логистичсекая регрессия с бейзлайном показывает нормальный результат, но recall уходящий за половину это не есть хорошо.\n"
      ],
      "metadata": {
        "id": "LASdqRQRwmX0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Улучшение бейзлайна"
      ],
      "metadata": {
        "id": "DLlwuRt9w-SQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Формулировка гипотез**\n",
        "\n",
        "**Гипотеза 1: Препроцессинг**\n",
        "\n",
        "Можно сделать более аккуратную подготовку данных: убрать явные выбросы по возрасту и стажу (например, person_age < 100, person_emp_length < 100), заполнить пропуски только в числовых колонках и заменить Label Encoding на One-hot encoding для категориальных признаков.\n",
        "\n",
        "**Гипотеза 2: Подбор гиперпараметров**\n",
        "\n",
        "Подобрать коэффициент регуляризации с помощью кросс-валидации по F1-Score. Проверить несколько значений C (например, 0.01, 0.1, 1, 10) и выбрать то, которое даёт лучший баланс Precision/Recall на обучающей выборке, более подходящая регуляризация поможет модели не переобучаться и чутка поднять качество на тесте.\n",
        "\n",
        "**Гипотеза 3: Учёт дисбаланса классов**\n",
        "\n",
        "Попробовать вариант с учётом дисбаланса через параметр class_weight='balanced'. Идея в том, что модель начнёт сильнее учитывать ошибки по дефолтным клиентам, которых меньше в выборки и таким образом  поднять Recall, пусть даже за счёт небольшого падения Precision и Accuracy.\n",
        "\n",
        "**Гипотеза 4: Сдвиг порога классификации**\n",
        "\n",
        "Вместо фиксированного порога 0.5 для вероятности дефолта попробовать подобрать порог по валидации (например, перебрать значения от 0.3 до 0.7 и посмотреть F1-Score и Recall). При более низком пороге модель начнёт ловить больше проблемных клиентов, пусть даже увеличится количество ложных срабатываний."
      ],
      "metadata": {
        "id": "zNOYWZf0yRem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Проверка гипотез**"
      ],
      "metadata": {
        "id": "EBPAKSe10q98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Загружаем датасет\n",
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Смотрим, сколько записей до удаления выбросов\n",
        "print(\"До удаления выбросов:\", len(df))\n",
        "\n",
        "# Удаляем явно странные значения по возрасту и стажу\n",
        "df = df[(df['person_age'] < 100) & (df['person_emp_length'] < 100)]\n",
        "\n",
        "print(\"После удаления выбросов:\", len(df))\n",
        "\n",
        "# Заполняем пропуски только в числовых колонках\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# One-hot encoding для категориальных признаков\n",
        "df = pd.get_dummies(\n",
        "    df,\n",
        "    columns=['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'],\n",
        "    drop_first=False\n",
        ")\n",
        "\n",
        "# Разделяем на признаки и целевой класс\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "print(f\"Количество признаков после One-hot: {X.shape[1]}\")\n",
        "\n",
        "# Делим данные на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# Масштабируем признаки\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Обучаем логистическую регрессию на данных после препроцессинга\n",
        "log_reg_prep = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    C=1.0,\n",
        "    n_jobs=-1,\n",
        "    solver='lbfgs'\n",
        ")\n",
        "log_reg_prep.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания и вероятности\n",
        "y_pred = log_reg_prep.predict(X_test)\n",
        "y_pred_proba = log_reg_prep.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# метрики\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(\"Гипотеза 1: препроцессинг\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pg8DKNC1EiW",
        "outputId": "f9105a87-f201-47f4-fdf6-38ef96de6715"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "До удаления выбросов: 32581\n",
            "После удаления выбросов: 31679\n",
            "Количество признаков после One-hot: 26\n",
            "Гипотеза 1: препроцессинг\n",
            "Accuracy: 0.8701\n",
            "Precision: 0.7748\n",
            "Recall: 0.5597\n",
            "F1-Score: 0.6499\n",
            "ROC-AUC: 0.8745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 1:**\n",
        "\n",
        "После удаления выбросов и перехода на One-hot encoding качество лог регрессии заметно подросло по всем основным метрикам по сравнению с базовым бейзлайном.\n",
        "\n",
        "Гипотезу можно считать удачной, берём.\n"
      ],
      "metadata": {
        "id": "lc7dZ7U01lpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 2: подбор гиперпараметров\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Набор значений C для проверки\n",
        "C_values = [0.01, 0.1, 1.0, 3.0, 10.0]\n",
        "results = []\n",
        "\n",
        "print(\"Проверка разных значений C (5-fold CV, F1-Score):\\n\")\n",
        "\n",
        "for C in C_values:\n",
        "    log_reg_cv = LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        C=C,\n",
        "        n_jobs=-1,\n",
        "        solver='lbfgs'\n",
        "    )\n",
        "    # Кросс-валидация по F1-Score\n",
        "    cv_scores = cross_val_score(\n",
        "        log_reg_cv,\n",
        "        X_train, y_train,\n",
        "        cv=5,\n",
        "        scoring='f1'\n",
        "    )\n",
        "    mean_score = cv_scores.mean()\n",
        "    results.append({'C': C, 'mean_f1': mean_score})\n",
        "    print(f\"C={C:4}: F1-Score (5-fold CV) = {mean_score:.4f}\")\n",
        "\n",
        "# Находим лучшее C по среднему F1\n",
        "best = max(results, key=lambda x: x['mean_f1'])\n",
        "best_C = best['C']\n",
        "best_f1_cv = best['mean_f1']\n",
        "\n",
        "print(f\"\\nЛучший C = {best_C} (F1-Score на кросс-валидации = {best_f1_cv:.4f})\")\n",
        "\n",
        "# Обучаем финальную модель с лучшим C\n",
        "log_reg_best = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    C=best_C,\n",
        "    n_jobs=-1,\n",
        "    solver='lbfgs'\n",
        ")\n",
        "log_reg_best.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания и вероятности на тесте\n",
        "y_pred = log_reg_best.predict(X_test)\n",
        "y_pred_proba = log_reg_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Метрики на тестовой выборке\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"\\nГипотеза 2: подбор C (C = {best_C})\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bectHevU5wNI",
        "outputId": "cd6dd270-0ad1-465d-acd1-61247033b340"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Проверка разных значений C (5-fold CV, F1-Score):\n",
            "\n",
            "C=0.01: F1-Score (5-fold CV) = 0.6320\n",
            "C= 0.1: F1-Score (5-fold CV) = 0.6397\n",
            "C= 1.0: F1-Score (5-fold CV) = 0.6394\n",
            "C= 3.0: F1-Score (5-fold CV) = 0.6394\n",
            "C=10.0: F1-Score (5-fold CV) = 0.6394\n",
            "\n",
            "Лучший C = 0.1 (F1-Score на кросс-валидации = 0.6397)\n",
            "\n",
            "Гипотеза 2: подбор C (C = 0.1)\n",
            "Accuracy: 0.8699\n",
            "Precision: 0.7757\n",
            "Recall: 0.5575\n",
            "F1-Score: 0.6488\n",
            "ROC-AUC: 0.8745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 2:**\n",
        "\n",
        "Подбор коэффицента через кросс-валидацию дал совсем небольшой, но всё-таки прирост по F1-Score. Фактически эта гипотеза не даёт какого‑то ощутимого усиления модели, но я понял, что лучше взять значение коэффицента 0.1\n",
        "\n",
        "Гипотезу 2 берём."
      ],
      "metadata": {
        "id": "IM_cLxbw7A-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 3: учет дисбаланса классов через class_weight='balanced'\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Используем те же X_train, X_test, y_train, y_test после препроцессинга (гипотеза 1)\n",
        "# и тот же лучший C из гипотезы 2 (best_C)\n",
        "\n",
        "print(f\"Используем C = {best_C} и class_weight='balanced'\")\n",
        "\n",
        "log_reg_balanced = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    C=best_C,\n",
        "    n_jobs=-1,\n",
        "    solver='lbfgs',\n",
        "    class_weight='balanced'\n",
        ")\n",
        "log_reg_balanced.fit(X_train, y_train)\n",
        "\n",
        "# Предсказания и вероятности\n",
        "y_pred = log_reg_balanced.predict(X_test)\n",
        "y_pred_proba = log_reg_balanced.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Метрики\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(\"Гипотеза 3: class_weight='balanced'\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPBoQkpX7Hzw",
        "outputId": "6236f24b-4496-404c-bf46-2170312fc344"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используем C = 0.1 и class_weight='balanced'\n",
            "Гипотеза 3: class_weight='balanced'\n",
            "Accuracy: 0.8123\n",
            "Precision: 0.5445\n",
            "Recall: 0.7890\n",
            "F1-Score: 0.6443\n",
            "ROC-AUC: 0.8763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 3**\n",
        "\n",
        "После включения class_weight='balanced' логистическая регрессия начала гораздо сильнее уделять внимание редкому классу, это видно по Recall, его показатели заметно выросли, но просадку по Accuracy и Precision я простить не могу, потому модель по сути помечает нормальных ребят как рискованных.\n",
        "\n",
        "Гипотеза 3 не подтверждена."
      ],
      "metadata": {
        "id": "IXpNKRSm8RaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гипотеза 4: сдвиг порога классификации\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Считаем вероятности дефолта для тестовой выборки\n",
        "y_proba_base = log_reg_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Набор порогов, которые будем проверять\n",
        "thresholds = np.arange(0.30, 0.71, 0.05)\n",
        "\n",
        "results_thr = []\n",
        "\n",
        "print(\"Проверка разных порогов для вероятности дефолта:\\n\")\n",
        "\n",
        "for thr in thresholds:\n",
        "    # Переводим вероятности в классы по заданному порогу\n",
        "    y_pred_thr = (y_proba_base >= thr).astype(int)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred_thr)\n",
        "    prec = precision_score(y_test, y_pred_thr)\n",
        "    rec = recall_score(y_test, y_pred_thr)\n",
        "    f1_thr = f1_score(y_test, y_pred_thr)\n",
        "\n",
        "    results_thr.append({\n",
        "        'thr': thr,\n",
        "        'accuracy': acc,\n",
        "        'precision': prec,\n",
        "        'recall': rec,\n",
        "        'f1': f1_thr\n",
        "    })\n",
        "\n",
        "    print(f\"Порог={thr:.2f} | Accuracy={acc:.4f} | Precision={prec:.4f} | Recall={rec:.4f} | F1={f1_thr:.4f}\")\n",
        "\n",
        "# Ищем порог с максимальным F1-Score\n",
        "best_thr_obj = max(results_thr, key=lambda x: x['f1'])\n",
        "best_thr = best_thr_obj['thr']\n",
        "\n",
        "print(f\"\\nЛучший порог по F1-Score: {best_thr:.2f}\")\n",
        "\n",
        "# Считаем метрики для лучшего порога ещё раз, аккуратно выводим\n",
        "y_pred_best_thr = (y_proba_base >= best_thr).astype(int)\n",
        "\n",
        "acc_best = accuracy_score(y_test, y_pred_best_thr)\n",
        "prec_best = precision_score(y_test, y_pred_best_thr)\n",
        "rec_best = recall_score(y_test, y_pred_best_thr)\n",
        "f1_best = f1_score(y_test, y_pred_best_thr)\n",
        "roc_auc_best = roc_auc_score(y_test, y_proba_base)  # ROC-AUC не зависит от порога\n",
        "\n",
        "print(f\"\\nГипотеза 4: сдвиг порога (threshold = {best_thr:.2f})\")\n",
        "print(f\"Accuracy: {acc_best:.4f}\")\n",
        "print(f\"Precision: {prec_best:.4f}\")\n",
        "print(f\"Recall: {rec_best:.4f}\")\n",
        "print(f\"F1-Score: {f1_best:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_best:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv3DnJvk8kLa",
        "outputId": "3a8344af-4a97-43ff-b8b2-71f84569f27f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Проверка разных порогов для вероятности дефолта:\n",
            "\n",
            "Порог=0.30 | Accuracy=0.8521 | Precision=0.6360 | Recall=0.7333 | F1=0.6812\n",
            "Порог=0.35 | Accuracy=0.8632 | Precision=0.6774 | Recall=0.6967 | F1=0.6869\n",
            "Порог=0.40 | Accuracy=0.8695 | Precision=0.7162 | Recall=0.6527 | F1=0.6830\n",
            "Порог=0.45 | Accuracy=0.8706 | Precision=0.7444 | Recall=0.6081 | F1=0.6694\n",
            "Порог=0.50 | Accuracy=0.8699 | Precision=0.7757 | Recall=0.5575 | F1=0.6488\n",
            "Порог=0.55 | Accuracy=0.8687 | Precision=0.8039 | Recall=0.5165 | F1=0.6289\n",
            "Порог=0.60 | Accuracy=0.8630 | Precision=0.8248 | Recall=0.4623 | F1=0.5925\n",
            "Порог=0.65 | Accuracy=0.8586 | Precision=0.8591 | Recall=0.4110 | F1=0.5560\n",
            "Порог=0.70 | Accuracy=0.8504 | Precision=0.8812 | Recall=0.3531 | F1=0.5042\n",
            "\n",
            "Лучший порог по F1-Score: 0.35\n",
            "\n",
            "Гипотеза 4: сдвиг порога (threshold = 0.35)\n",
            "Accuracy: 0.8632\n",
            "Precision: 0.6774\n",
            "Recall: 0.6967\n",
            "F1-Score: 0.6869\n",
            "ROC-AUC: 0.8745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 4**\n",
        "\n",
        "Перебор порогов показал, что оптимальное значение 0.35, есть баланс между метриками.\n",
        "\n",
        "Гипотезу 4 берём.\n"
      ],
      "metadata": {
        "id": "CSzVK3ZM89oS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c., d и e. Формирование, обучение и оценка качества улучшенного бейзлайна**"
      ],
      "metadata": {
        "id": "uK5_u6689XTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Улучшенный бейзлайн логистической регрессии\n",
        "# Гипотеза 1 (препроцессинг + One-hot) + гипотеза 2 (C=0.1) + гипотеза 4 (порог 0.35)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Загружаем датасет\n",
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Удаляем выбросы по возрасту и стажу\n",
        "df = df[(df['person_age'] < 100) & (df['person_emp_length'] < 100)]\n",
        "\n",
        "# Заполняем пропуски в числовых колонках\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# One-hot encoding для категориальных признаков\n",
        "df = pd.get_dummies(\n",
        "    df,\n",
        "    columns=['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'],\n",
        "    drop_first=False\n",
        ")\n",
        "\n",
        "# Разделяем на признаки и целевой класс\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "# Делим на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# Масштабируем признаки\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Обучаем логистическую регрессию с подобранным C\n",
        "log_reg_final = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    C=0.1,\n",
        "    n_jobs=-1,\n",
        "    solver='lbfgs'\n",
        ")\n",
        "log_reg_final.fit(X_train, y_train)\n",
        "\n",
        "# Получаем вероятности дефолта\n",
        "y_proba = log_reg_final.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Используем порог из гипотезы 4\n",
        "threshold = 0.35\n",
        "y_pred = (y_proba >= threshold).astype(int)\n",
        "\n",
        "# Метрики\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "print(\"Улучшенный бейзлайн\")\n",
        "print(f\"Порог: {threshold}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVb6R99F9kDs",
        "outputId": "cfb43751-47c1-457e-eb3e-b7de391b5fdc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Улучшенный бейзлайн\n",
            "Порог: 0.35\n",
            "Accuracy: 0.8632\n",
            "Precision: 0.6774\n",
            "Recall: 0.6967\n",
            "F1-Score: 0.6869\n",
            "ROC-AUC: 0.8745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f. Сравнение результатов с пунктом 2:**\n",
        "\n",
        "Базовый бейзлайн:\n",
        "\n",
        "- Accuracy: 0.8449  \n",
        "- Precision: 0.7241  \n",
        "- Recall: 0.4669  \n",
        "- F1-Score: 0.5678  \n",
        "- ROC-AUC: 0.8516  \n",
        "\n",
        "Улучшенный бейзлайн:\n",
        "\n",
        "- Accuracy: 0.8632  \n",
        "- Precision: 0.6774  \n",
        "- Recall: 0.6967  \n",
        "- F1-Score: 0.6869  \n",
        "- ROC-AUC: 0.8745  \n",
        "\n",
        "По сравнению с базовым бейзлайном Recall вырос примерно с 0.47 до 0.70, а F1-Score с 0.57 до 0.69, то есть модель стала намного лучше ловить дефолты и в целом точнее работать с проблемным классом. Accuracy тоже немного подрос (с 0.84 до 0.86), ROC-AUC улучшился, а вот Precision ожидаемо чуть просел, так как модель стала чаще относить клиентов к дефолтным."
      ],
      "metadata": {
        "id": "l8_5wnqz-sPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**g. Выводы**\n",
        "\n",
        "Логистическая регрессия в базовом виде дала более‑менее рабочий результат, но сильно проседала по Recall: почти половина дефолтов оставалась незамеченной. После нормального препроцессинга (удаление выбросов, One-hot для категориальных признаков), подбора коэффицента и настройки порога качества стало заметно лучше: выросли Recall и F1-Score, немного подтянулись Accuracy и ROC-AUC."
      ],
      "metadata": {
        "id": "XNYrQjZE-23b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Имплементация алгоритма машинного обучения"
      ],
      "metadata": {
        "id": "LPCwqP5s_Wko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Имплементация логистической регрессии**"
      ],
      "metadata": {
        "id": "OVjrPaKk_fSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LogisticRegressionCustom:\n",
        "\n",
        "    def __init__(self, lr=0.01, n_iter=2000):\n",
        "        \"\"\"\n",
        "        lr: скорость обучения\n",
        "        n_iter: количество итераций градиентного спуска\n",
        "        \"\"\"\n",
        "        self.lr = lr\n",
        "        self.n_iter = n_iter\n",
        "        self.w = None  # веса\n",
        "        self.b = None  # свободный член\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        \"\"\"Сигмоида для перевода линейной комбинации признаков в вероятность.\"\"\"\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Обучение модели на тренировочных данных.\n",
        "        X: матрица признаков (num_samples x num_features)\n",
        "        y: вектор меток (0/1)\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Инициализируем веса нулями\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0.0\n",
        "\n",
        "        # Градиентный спуск\n",
        "        for _ in range(self.n_iter):\n",
        "            # Линейная комбинация признаков\n",
        "            linear = np.dot(X, self.w) + self.b\n",
        "            # Преобразуем в вероятности\n",
        "            y_pred = self.sigmoid(linear)\n",
        "\n",
        "            # Градиенты по w и b (производные логистической потерь)\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
        "\n",
        "            # Обновляем параметры\n",
        "            self.w -= self.lr * dw\n",
        "            self.b -= self.lr * db\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Возвращает вероятность класса 1 для каждого объекта.\"\"\"\n",
        "        linear = np.dot(X, self.w) + self.b\n",
        "        return self.sigmoid(linear)\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        \"\"\"\n",
        "        Предсказываем классы (0/1) по заданному порогу.\n",
        "        По умолчанию порог 0.5.\n",
        "        \"\"\"\n",
        "        proba = self.predict_proba(X)\n",
        "        return (proba >= threshold).astype(int)"
      ],
      "metadata": {
        "id": "BC3WvqCR_nOk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Обучение имплементированной модели с базовым бейзлайном**"
      ],
      "metadata": {
        "id": "W2Dwx14BAB1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Загружаем датасет\n",
        "df_base = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Кодируем категориальные признаки (как в базовом бейзлайне из пункта 2)\n",
        "for col in ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']:\n",
        "    le = LabelEncoder()\n",
        "    df_base[col] = le.fit_transform(df_base[col])\n",
        "\n",
        "# Заполняем пропуски медианой по числовым колонкам\n",
        "df_base = df_base.fillna(df_base.median(numeric_only=True))\n",
        "\n",
        "# Разделяем на признаки и целевой класс\n",
        "X_base = df_base.drop('loan_status', axis=1)\n",
        "y_base = df_base['loan_status']\n",
        "\n",
        "# Делим на train/test\n",
        "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(\n",
        "    X_base, y_base,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_base\n",
        ")\n",
        "\n",
        "# Масштабируем признаки\n",
        "scaler_base = StandardScaler()\n",
        "X_train_base = scaler_base.fit_transform(X_train_base)\n",
        "X_test_base = scaler_base.transform(X_test_base)\n",
        "\n",
        "# Переводим в numpy\n",
        "X_train_base = np.array(X_train_base)\n",
        "X_test_base = np.array(X_test_base)\n",
        "y_train_base = np.array(y_train_base)\n",
        "y_test_base = np.array(y_test_base)\n",
        "\n",
        "# Обучаем имплементированную логистическую регрессию\n",
        "log_reg_custom_base = LogisticRegressionCustom(lr=0.01, n_iter=2000)\n",
        "log_reg_custom_base.fit(X_train_base, y_train_base)\n",
        "\n",
        "print(\"Имплементированная логистическая регрессия на базовом бейзлайне обучена\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpF_KurBADcF",
        "outputId": "93619bae-42fd-41ce-c05d-1a9b1f6fec5d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Имплементированная логистическая регрессия на базовом бейзлайне обучена\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c. Оценка качества имплементированной модели с базовым бейзлайном**"
      ],
      "metadata": {
        "id": "FNNOK4XLSs6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказания на тестовой выборке с порогом 0.5\n",
        "y_pred_base = log_reg_custom_base.predict(X_test_base, threshold=0.5)\n",
        "y_proba_base = log_reg_custom_base.predict_proba(X_test_base)\n",
        "\n",
        "print(\"Логистическая регрессия (базовый бейзлайн)\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_base, y_pred_base):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_base, y_pred_base):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_base, y_pred_base):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test_base, y_pred_base):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test_base, y_proba_base):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIOxNv5FBXBY",
        "outputId": "57486922-83fe-42cd-ea43-696136f823b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Логистическая регрессия (базовый бейзлайн)\n",
            "Accuracy: 0.8438\n",
            "Precision: 0.7306\n",
            "Recall: 0.4501\n",
            "F1-Score: 0.5570\n",
            "ROC-AUC: 0.8467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d. Сравнение результатов с пунктом 2**\n",
        "\n",
        "В пункте 2 библиотечная логистическая регрессия давала такие метрики: Accuracy = 0.8449, Precision = 0.7241, Recall = 0.4669, F1-Score = 0.5678, ROC-AUC = 0.8516.​​ У моей логистической регрессии на том же базовом бейзлайне получились очень близкие значения: Accuracy = 0.8438, Precision = 0.7306, Recall = 0.4501, F1-Score = 0.5570, ROC-AUC = 0.8467.\n",
        "\n",
        "Разница по всем метрикам укладывается в несколько сотых: где‑то чуть выше Precision, где‑то чуть ниже Recall и ROC-AUC, но общая картина совпадает, так что результаты ожидаемы."
      ],
      "metadata": {
        "id": "JTHsa76kBkVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e. Выводы**\n",
        "\n",
        "Реализованная логистическая регрессия на базовом ведёт себя так же, как и библиотечная версия из sklearn: метрики отличаются совсем немного и показывают тот же уровень качества.​"
      ],
      "metadata": {
        "id": "JNLgEg9bB-Z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f. и g. Добавление техник из улучшенного бейзлайна и обучение имплементированной модели**"
      ],
      "metadata": {
        "id": "wh4L82rQCFnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавление техник из улучшенного бейзлайна и обучение\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Загружаем датасет\n",
        "df = pd.read_csv('credit_risk_dataset.csv')\n",
        "\n",
        "# Удаляем выбросы по возрасту и стажу\n",
        "df = df[(df['person_age'] < 100) & (df['person_emp_length'] < 100)]\n",
        "\n",
        "# Заполняем пропуски только в числовых колонках\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# One-hot encoding для категориальных признаков\n",
        "df = pd.get_dummies(\n",
        "    df,\n",
        "    columns=['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'],\n",
        "    drop_first=False\n",
        ")\n",
        "\n",
        "# Разделяем на признаки и целевой класс\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "# Делим на train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# Масштабируем признаки\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Переводим в numpy\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Обучаем логистическую регрессию на улучшенном бейзлайне\n",
        "log_reg_custom_improved = LogisticRegressionCustom(lr=0.01, n_iter=2000)\n",
        "log_reg_custom_improved.fit(X_train, y_train)\n",
        "\n",
        "print(\"Логистическая регрессия (улучшенный бейзлайн) обучена\")\n",
        "print(\"Размер тестового набора:\", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3VSKhtXCtTD",
        "outputId": "893a59c2-15af-4119-f28c-c0096a89d0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Логистическая регрессия (улучшенный бейзлайн) обучена\n",
            "Размер тестового набора: 6336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**h. Оценка качества имплементированной модели с улучшенным бейзлайном**"
      ],
      "metadata": {
        "id": "k5daWdyZDIEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Порог взяли из гипотезы 4\n",
        "threshold = 0.35\n",
        "\n",
        "# Вероятности и предсказания\n",
        "y_proba_improved = log_reg_custom_improved.predict_proba(X_test)\n",
        "y_pred_improved = (y_proba_improved >= threshold).astype(int)\n",
        "\n",
        "print(\"Логистическая регрессия (улучшенный бейзлайн)\")\n",
        "print(f\"Порог: {threshold}\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_improved):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_improved):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_improved):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred_improved):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba_improved):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvPbKQIjDYZG",
        "outputId": "ea9ddb85-4ff8-491a-c95e-2f72877d36ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Логистическая регрессия (улучшенный бейзлайн)\n",
            "Порог: 0.35\n",
            "Accuracy: 0.8562\n",
            "Precision: 0.6523\n",
            "Recall: 0.7121\n",
            "F1-Score: 0.6809\n",
            "ROC-AUC: 0.8710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**i. Сравнение результатов c пунктом 3**\n",
        "\n",
        "В пункте 3 для улучшенного бейзлайна логистической регрессии из sklearn метрики были такими: Accuracy = 0.8632, Precision = 0.6774, Recall = 0.6967, F1-Score = 0.6869, ROC-AUC = 0.8745.​​ У реализованной мною логистической регрессии получилось: Accuracy = 0.8562, Precision = 0.6523, Recall = 0.7121, F1-Score = 0.6809, ROC-AUC = 0.8710.\n",
        "\n",
        "Получается, что собственная реализация показала примерно те жже цифры: Recall даже немного выше (0.7121 против 0.6967), а Accuracy, Precision, F1 и ROC-AUC чуть ниже, но в пределах пары сотых."
      ],
      "metadata": {
        "id": "wUsNxKLcD9Ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**j. Выводы**\n",
        "\n",
        "Логистическая регрессия, реализованная вручную, на улучшенном бейзлайне показывает качество, сопоставимое с библиотечной моделью: и по базовому варианту, и после добавления препроцессинга и настройки порога метрики остаются на том же уровне, что подтверждает корректную имплементацию."
      ],
      "metadata": {
        "id": "JyUqUi-BEGgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Регрессия"
      ],
      "metadata": {
        "id": "-h0N8WQOpLD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Создание бейзлайна и оценка качества"
      ],
      "metadata": {
        "id": "SaQW7_5PpRtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Обучение модели sklearn**"
      ],
      "metadata": {
        "id": "PuLqjTI0rGaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Загружаем датасет\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "\n",
        "# Уберём лишние столбцы, которые сейчас использовать не будем\n",
        "# (дата записи и тренд зарплаты по времени)\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# Категориальные признаки в датасете\n",
        "cat_cols = ['Company_Name', 'Job_Role', 'Experience_Level', 'City']\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Заполняем возможные пропуски медианой по числовым колонкам\n",
        "df = df.fillna(df.median(numeric_only=True))\n",
        "\n",
        "# Признаки и целевая переменная\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "# Разделение на train / test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Масштабирование признаков\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Базовая модель: линейная регрессия\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Предсказания на тестовой выборке\n",
        "y_pred = linreg.predict(X_test_scaled)\n",
        "\n",
        "# Метрики качества\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "print(\"Линейная регрессия (бейзлайн)\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptPEevmTr-SE",
        "outputId": "1a424700-7a0f-4e8e-a9b5-512914534dc3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Линейная регрессия (бейзлайн)\n",
            "MAE:  593488.92\n",
            "RMSE: 791551.53\n",
            "R²:   0.0047\n",
            "MAPE: 60.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Оценка качества модели**\n",
        "\n",
        "Линейная регрессия в базовой конфигурации предсказывает зарплаты довольно грубо: средняя абсолютная ошибка почти 600 тысяч рупий, RMSE ещё выше (около 790 тысяч), а MAPE около 61%, то есть модель в среднем промахивается по зарплате примерно на 60% от реального значения.  При этом R² ≈ 0.0047 практически равен нулю, что говорит о том, что текущий набор признаков и простой Label Encoding почти не объясняют разброс зарплат в датасете. Надо улучшать, идём дальше."
      ],
      "metadata": {
        "id": "EniC7_FHtV57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Улучшение бейзлайна"
      ],
      "metadata": {
        "id": "TOJgSqv2tpms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Формулирование гипотез**\n",
        "\n",
        "**Гипотеза 1: Препроцессинг**\n",
        "\n",
        "Удаление выбросов по Salary_INR (например, оставив значения между 1% и 99% перцентилями) и замена LabelEncoder на OneHotEncoder улучшат качество, так как линейная модель чувствительна к выбросам и неверной интерпретации категорий как чисел.\n",
        "\n",
        "**Гипотеза 2: Новые признаки**\n",
        "\n",
        "Добавление осмысленных признаков (avg_salary_by_city, avg_salary_by_role, demand_remote_ratio), которые уже показали себя в первой лабе, поможет модели уловить скрытые зависимости и улучшит предсказания, так как эти признаки несут в себе больше контекста, чем исходные.\n",
        "\n",
        "**Гипотеза 3: Логарифмирование цели**\n",
        "\n",
        "Логарифмирование Salary_INR сделает распределение целевой переменной более похожим на нормальное, что стабилизирует линейную модель, уменьшит влияние экстремально высоких зарплат и улучшит метрики, особенно MAPE и R².​​\n",
        "\n",
        "**Гипотеза 4: Полиномиальные признаки:**\n",
        "\n",
        "Возможно, зависимость зарплаты от некоторых числовых признаков (например, Demand_Index) нелинейная. Если добавить полиномиальные признаки (например, квадраты исходных числовых фичей), то линейная модель сможет уловить эту нелинейность, что приведёт к росту R²."
      ],
      "metadata": {
        "id": "1KEH4vR9t2l6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Проверка гипотез**"
      ],
      "metadata": {
        "id": "JzwYq1guwhpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Загружаем заново\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "\n",
        "# Дропаем лишнее\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# 1. Удаление выбросов (оставляем с 1-го по 99-й перцентиль)\n",
        "print(f\"Размер датасета до удаления выбросов: {len(df)}\")\n",
        "q1 = df['Salary_INR'].quantile(0.01)\n",
        "q99 = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q1) & (df['Salary_INR'] <= q99)]\n",
        "print(f\"Размер датасета после удаления выбросов: {len(df)}\")\n",
        "\n",
        "# Заполняем пропуски\n",
        "df = df.fillna(df.median(numeric_only=True))\n",
        "\n",
        "# 2. One-hot encoding\n",
        "cat_cols = ['Company_Name', 'Job_Role', 'Experience_Level', 'City']\n",
        "df = pd.get_dummies(df, columns=cat_cols, drop_first=False)\n",
        "\n",
        "# Признаки и цель\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "print(f\"Количество признаков после One-hot: {X.shape[1]}\")\n",
        "\n",
        "# Train / Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Линейная регрессия\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = linreg.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "print(\"Линейная регрессия (Гипотеза 1: выбросы + One-hot)\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZN1ThpWwnV8",
        "outputId": "fa4d4f0d-515f-4ce8-b647-72d479f7c1e1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер датасета до удаления выбросов: 30000\n",
            "Размер датасета после удаления выбросов: 29400\n",
            "Количество признаков после One-hot: 66\n",
            "Линейная регрессия (Гипотеза 1: выбросы + One-hot)\n",
            "MAE:  391436.04\n",
            "RMSE: 489428.13\n",
            "R²:   0.5437\n",
            "MAPE: 39.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 1:**\n",
        "\n",
        "После того как удалили 1% самых маленьких и самых больших зарплат и заменили LabelEncoder на OneHotEncoder, метрики заметно улучшились.\n",
        "\n",
        "Гипотезу 1 используем."
      ],
      "metadata": {
        "id": "CXVe9EXwxBUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Загружаем датасет\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# 1. Удаление выбросов (1-99 перцентиль)\n",
        "q1 = df['Salary_INR'].quantile(0.01)\n",
        "q99 = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q1) & (df['Salary_INR'] <= q99)]\n",
        "\n",
        "# Заполнение пропусков медианой\n",
        "df = df.fillna(df.median(numeric_only=True))\n",
        "\n",
        "# 2. Новые признаки\n",
        "# Средняя зарплата по городу и по роли\n",
        "df['avg_salary_by_city'] = df.groupby('City')['Salary_INR'].transform('mean')\n",
        "df['avg_salary_by_role'] = df.groupby('Job_Role')['Salary_INR'].transform('mean')\n",
        "\n",
        "# Комбинация спроса и удалёнки\n",
        "df['demand_remote_ratio'] = df['Demand_Index'] * (df['Remote_Option_Flag'] + 1)\n",
        "\n",
        "print(\"Примеры новых признаков:\")\n",
        "print(f\"- avg_salary_by_city (min/max): {df['avg_salary_by_city'].min():.0f} / {df['avg_salary_by_city'].max():.0f}\")\n",
        "print(f\"- demand_remote_ratio (min/max): {df['demand_remote_ratio'].min()} / {df['demand_remote_ratio'].max()}\")\n",
        "\n",
        "# 3. One-hot encoding\n",
        "df = pd.get_dummies(df, columns=['Company_Name', 'Job_Role', 'Experience_Level', 'City'], drop_first=False)\n",
        "\n",
        "# Разделение X и y\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "print(f\"Признаков после One-hot и добавления новых: {X.shape[1]}\")\n",
        "\n",
        "# Train / Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Масштабирование\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Обучение линейной регрессии\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Предсказание и метрики\n",
        "y_pred = linreg.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "print(\"Линейная регрессия (Гипотеза 2: новые признаки)\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ucDzLN_xCjE",
        "outputId": "25a809a2-5edb-4010-bc71-5fac848c8d16"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Примеры новых признаков:\n",
            "- avg_salary_by_city (min/max): 1255915 / 1296444\n",
            "- demand_remote_ratio (min/max): 10 / 198\n",
            "Признаков после One-hot и добавления новых: 69\n",
            "Линейная регрессия (Гипотеза 2: новые признаки)\n",
            "MAE:  391475.43\n",
            "RMSE: 489404.83\n",
            "R²:   0.5438\n",
            "MAPE: 39.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 2:**\n",
        "\n",
        "Добавление новых признаков практически ничего не изменило. Метрики остались почти такими же, как в первой гипотезе: MAE около 391 тысячи, R² замер на уровне 0.5438 (был 0.5437).​ Видимо, для линейной регрессии эти признаки оказались избыточными.\n",
        "\n",
        "Гипотеза 2 неудачная."
      ],
      "metadata": {
        "id": "6cJJTOpDxvrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# 1. Удаление выбросов\n",
        "q1 = df['Salary_INR'].quantile(0.01)\n",
        "q99 = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q1) & (df['Salary_INR'] <= q99)]\n",
        "df = df.fillna(df.median(numeric_only=True))\n",
        "\n",
        "# 2. Логарифмирование цели (log1p)\n",
        "df['Salary_INR_log'] = np.log1p(df['Salary_INR'])\n",
        "\n",
        "print(f\"Зарплата (min/max): {df['Salary_INR'].min():.0f} / {df['Salary_INR'].max():.0f}\")\n",
        "print(f\"Log зарплаты (min/max): {df['Salary_INR_log'].min():.2f} / {df['Salary_INR_log'].max():.2f}\")\n",
        "\n",
        "# 3. One-hot encoding\n",
        "df = pd.get_dummies(df, columns=['Company_Name', 'Job_Role', 'Experience_Level', 'City'], drop_first=False)\n",
        "\n",
        "# Убираем исходную зарплату из признаков, предсказываем логарифм\n",
        "X = df.drop(['Salary_INR', 'Salary_INR_log'], axis=1)\n",
        "y_log = df['Salary_INR_log']\n",
        "y_original = df['Salary_INR']\n",
        "\n",
        "# Сплит\n",
        "X_train, X_test, y_train_log, y_test_log, y_train_orig, y_test_orig = train_test_split(\n",
        "    X, y_log, y_original, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Линейная регрессия на логарифме\n",
        "linreg_log = LinearRegression()\n",
        "linreg_log.fit(X_train_scaled, y_train_log)\n",
        "\n",
        "# Предсказание логарифма\n",
        "y_pred_log = linreg_log.predict(X_test_scaled)\n",
        "\n",
        "# Возвращаем предсказания в обычную шкалу\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "\n",
        "# Метрики считаем на исходных (реальных) деньгах\n",
        "mae = mean_absolute_error(y_test_orig, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred))\n",
        "r2 = r2_score(y_test_orig, y_pred)\n",
        "mape = np.mean(np.abs((y_test_orig - y_pred) / y_test_orig)) * 100\n",
        "\n",
        "print(\"Линейная регрессия (Гипотеза 3: log цели)\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6O6oWt8x6gc",
        "outputId": "d4350e10-f743-4f13-a9f9-62c997cfcaa9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Зарплата (min/max): 338096 / 3974203\n",
            "Log зарплаты (min/max): 12.73 / 15.20\n",
            "Линейная регрессия (Гипотеза 3: log цели)\n",
            "MAE:  394710.10\n",
            "RMSE: 496156.72\n",
            "R²:   0.5311\n",
            "MAPE: 36.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 3:**\n",
        "\n",
        "Логарифмирование зарплаты сработало 50 на 50. С одной стороны, MAPE заметно снизился 36.70% против 39.19% в первой гипотезе. Это логично: логарифм сглаживает большие зарплаты, и модель начинает меньше ошибаться в процентах.\n",
        "\n",
        "С другой стороны, R² (0.5311) и MAE (394 710) стали даже чуть хуже, чем в гипотезе 1 (там было R² 0.5437 и MAE 391 436). То есть в рублях мы ошибаемся чуть сильнее, но относительная ошибка стала меньше. Приём полезный, но не идеальный, выигрываем только в одной метрике.\n",
        "\n",
        "Гипотезу 3 не берём."
      ],
      "metadata": {
        "id": "nfH1zz4Nycxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Загружаем датасет\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# 1. Удаление выбросов\n",
        "q1 = df['Salary_INR'].quantile(0.01)\n",
        "q99 = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q1) & (df['Salary_INR'] <= q99)]\n",
        "df = df.fillna(df.median(numeric_only=True))\n",
        "\n",
        "# 2. Добавляем полиномиальные признаки для Demand_Index\n",
        "# Просто возведем в квадрат вручную\n",
        "df['Demand_Index_Squared'] = df['Demand_Index'] ** 2\n",
        "\n",
        "# взаимодействие спроса и удаленки\n",
        "df['Demand_Remote_Interact'] = df['Demand_Index'] * df['Remote_Option_Flag']\n",
        "\n",
        "print(\"Новые признаки:\")\n",
        "print(df[['Demand_Index', 'Demand_Index_Squared', 'Demand_Remote_Interact']].head())\n",
        "\n",
        "# 3. One-hot encoding\n",
        "df = pd.get_dummies(df, columns=['Company_Name', 'Job_Role', 'Experience_Level', 'City'], drop_first=False)\n",
        "\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "# Train / Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Обучение\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = linreg.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "print(\"Линейная регрессия (Гипотеза 4: полиномиальные признаки)\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR1P0l6cydkT",
        "outputId": "3bd1c46a-2da4-4986-e08a-7a6dcc11c97c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Новые признаки:\n",
            "   Demand_Index  Demand_Index_Squared  Demand_Remote_Interact\n",
            "0            71                  5041                       0\n",
            "1            81                  6561                       0\n",
            "2            94                  8836                       0\n",
            "3            94                  8836                      94\n",
            "4            35                  1225                       0\n",
            "Линейная регрессия (Гипотеза 4: полиномиальные признаки)\n",
            "MAE:  391484.47\n",
            "RMSE: 489417.00\n",
            "R²:   0.5437\n",
            "MAPE: 39.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по гипотезе 4:**\n",
        "\n",
        "Добавление полиномиальных признаков (Demand_Index^2) и взаимодействия спроса с удалёнкой не дало никакого прироста. Метрики остались абсолютно такими же (R² = 0.5437, MAE = 391 484). Видимо, зависимость зарплаты от спроса либо достаточно линейная, либо эти признаки просто теряются на фоне остальных факторов (города, компании). Усложнять модель этими признаками нет смысла.\n",
        "\n",
        "Гипотеза 4 отвергается."
      ],
      "metadata": {
        "id": "RRF1fySKzJ_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. и d. Формирование улучшенного бейзлайна и обучение модели"
      ],
      "metadata": {
        "id": "2luVPaUfzgLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# 1. Загрузка и очистка\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# Удаление выбросов (1-99 перцентиль)\n",
        "q1 = df['Salary_INR'].quantile(0.01)\n",
        "q99 = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q1) & (df['Salary_INR'] <= q99)]\n",
        "\n",
        "# Заполнение пропусков\n",
        "df = df.fillna(df.median(numeric_only=True))\n",
        "\n",
        "# 2. One-hot encoding (основа улучшенного бейзлайна)\n",
        "df = pd.get_dummies(df, columns=['Company_Name', 'Job_Role', 'Experience_Level', 'City'], drop_first=False)\n",
        "\n",
        "# Разделение\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Масштабирование\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Обучение\n",
        "linreg_best = LinearRegression()\n",
        "linreg_best.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Модель с улучшенным бейзлайном обучена.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl9g16E9z-xY",
        "outputId": "3eb8ffb5-60b4-46c5-ca27-02c488d7273d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель с улучшенным бейзлайном обучена.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e. Оценка качества моделей с улучшенным бейзлайном**"
      ],
      "metadata": {
        "id": "muGDNl6y0KTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказание\n",
        "y_pred_best = linreg_best.predict(X_test_scaled)\n",
        "\n",
        "# Метрики\n",
        "mae = mean_absolute_error(y_test, y_pred_best)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
        "r2 = r2_score(y_test, y_pred_best)\n",
        "mape = np.mean(np.abs((y_test - y_pred_best) / y_test)) * 100\n",
        "\n",
        "print(\"Линейная регрессия (Улучшенный бейзлайн)\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSftARUA0RDp",
        "outputId": "8d42cbf3-ff52-44bd-c754-f105806b54b4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Линейная регрессия (Улучшенный бейзлайн)\n",
            "MAE:  391436.04\n",
            "RMSE: 489428.13\n",
            "R²:   0.5437\n",
            "MAPE: 39.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f. Сравнение результатов с пунктом 2**\n",
        "\n",
        "Базовый:\n",
        "\n",
        "MAE: 593 488.92\n",
        "\n",
        "RMSE: 791 551.53\n",
        "\n",
        "R²: 0.0047\n",
        "\n",
        "MAPE: 60.97%\n",
        "\n",
        "После улучшений:\n",
        "\n",
        "MAE: 391 436.04\n",
        "\n",
        "RMSE: 489 428.13\n",
        "\n",
        "R²: 0.5437\n",
        "\n",
        "MAPE: 39.19%\n",
        "\n",
        "Все четыре метрики существенно улучшились. Основной прирост дало именно правильное кодирование категорий: Label Encoding заставлял модель искать зависимость между зарплатой и номерами городов/компаний, чего на самом деле не существует. One-hot разбил каждую категорию на отдельные бинарные признаки, и модель начала нормально работать."
      ],
      "metadata": {
        "id": "fz8IPZVN1nGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e. Выводы**"
      ],
      "metadata": {
        "id": "4OmgY3Ot18aN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В линейной регрессии очень важно правильно кодировать категориальные признаки. С Label Encoding модель почти не работала, R² был около нуля. Когда я перешёл на One-hot, R² сразу вырос до 0.54, и модель начала лучше объяснять данные.\n",
        "\n",
        "Удаление выбросов тоже сильно помогло. Слишком большие и слишком маленькие зарплаты мешали модели, и после их удаления ошибки заметно снизились. MAPE уменьшился с 61% до 39%.\n",
        "\n",
        "В итоге линейная регрессия стала работать гораздо лучше, хотя точность всё ещё средняя, но для такой модели это нормально."
      ],
      "metadata": {
        "id": "q5OhVp_12HjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Имплементация алгоритма машинного обучения"
      ],
      "metadata": {
        "id": "DnzlMEP_2LS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Имплементация линейной регрессии**"
      ],
      "metadata": {
        "id": "mGb7ixSC2sk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LinearRegressionCustom:\n",
        "\n",
        "    def __init__(self, lr=0.01, n_iter=1000):\n",
        "        \"\"\"\n",
        "        lr: скорость обучения\n",
        "        n_iter: количество итераций градиентного спуска\n",
        "        \"\"\"\n",
        "        self.lr = lr\n",
        "        self.n_iter = n_iter\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Обучение модели на данных X, y.\n",
        "        X: матрица признаков (numpy array)\n",
        "        y: целевая переменная (numpy array)\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Инициализируем веса нулями\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0.0\n",
        "\n",
        "        # Градиентный спуск\n",
        "        for _ in range(self.n_iter):\n",
        "            # Предсказания модели\n",
        "            y_pred = X @ self.w + self.b\n",
        "\n",
        "            # Градиенты по w и b\n",
        "            dw = (2 / n_samples) * (X.T @ (y_pred - y))\n",
        "            db = (2 / n_samples) * np.sum(y_pred - y)\n",
        "\n",
        "            # Обновляем параметры\n",
        "            self.w -= self.lr * dw\n",
        "            self.b -= self.lr * db\n",
        "\n",
        "        print(\"Обучение завершено\")\n",
        "        print(\"Форма вектора весов:\", self.w.shape)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Предсказание значений для новых объектов X.\n",
        "        \"\"\"\n",
        "        return X @ self.w + self.b"
      ],
      "metadata": {
        "id": "aE9aFzda2yNQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. и c. Обучение и оценка имплементированной модели с базовым бейзлайном**"
      ],
      "metadata": {
        "id": "79Lkx6U229fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Загружаем датасет\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# Простой Label Encoding для категориальных признаков\n",
        "cat_cols = ['Company_Name', 'Job_Role', 'Experience_Level', 'City']\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Заполняем пропуски медианой по числовым колонкам\n",
        "df = df.fillna(df.median(numeric_only=True))\n",
        "\n",
        "# Признаки и целевая переменная\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "# Train / Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Масштабирование признаков\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Преобразуем в numpy-массивы\n",
        "X_train_scaled = np.array(X_train_scaled)\n",
        "X_test_scaled = np.array(X_test_scaled)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Обучаем\n",
        "linreg_custom_base = LinearRegressionCustom(lr=0.01, n_iter=1000)\n",
        "linreg_custom_base.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Предсказания и метрики\n",
        "y_pred_base = linreg_custom_base.predict(X_test_scaled)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred_base)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_base))\n",
        "r2 = r2_score(y_test, y_pred_base)\n",
        "mape = np.mean(np.abs((y_test - y_pred_base) / y_test)) * 100\n",
        "\n",
        "print(\"Линейная регрессия с имплементацией (базовый бейзлайн)\")\n",
        "print(f\"MAE:  {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyN1ZSew3Y5Z",
        "outputId": "060e1fb0-bcfd-42c5-e435-b0fc01f13e02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение завершено\n",
            "Форма вектора весов: (6,)\n",
            "Линейная регрессия с имплементацией (базовый бейзлайн)\n",
            "MAE:  593488.91\n",
            "RMSE: 791551.53\n",
            "R²:   0.0047\n",
            "MAPE: 60.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d. Сравнение результатов с пунктом 2**\n",
        "\n",
        "**Имплементированный:**\n",
        "\n",
        "MAE:  593488.91\n",
        "\n",
        "RMSE: 791551.53\n",
        "\n",
        "R²:   0.0047\n",
        "\n",
        "MAPE: 60.97\n",
        "\n",
        "**Sklearn:**\n",
        "\n",
        "MAE:  593488.92\n",
        "\n",
        "RMSE: 791551.53\n",
        "\n",
        "R²:   0.0047\n",
        "\n",
        "MAPE: 60.97\n",
        "\n",
        "Результаты преедельно схожи, если не сказать одинаковы."
      ],
      "metadata": {
        "id": "cbIS8N8v5Ij3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e. Выводы**\n",
        "\n",
        "Реализованный класс линейной регрессии показывает себя так же, как и стандартная библиотечная модель: на сырых данных с Label Encoding обе работают плохо. Это подтверждает, что проблема была не в алгоритме, а в подготовке данных."
      ],
      "metadata": {
        "id": "xDqR5noI6W-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f. и g. Добавление техник из улучшенного бейзлайна и обучение имплементированной модели**"
      ],
      "metadata": {
        "id": "JC8XT02i6wo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Загружаем датасет\n",
        "df = pd.read_csv('Job_Market_India.csv')\n",
        "df = df.drop(['Record_Date', 'Salary_Trend_Pct'], axis=1)\n",
        "\n",
        "# Удаляем выбросы (1-99 перцентили)\n",
        "q1 = df['Salary_INR'].quantile(0.01)\n",
        "q99 = df['Salary_INR'].quantile(0.99)\n",
        "df = df[(df['Salary_INR'] >= q1) & (df['Salary_INR'] <= q99)]\n",
        "\n",
        "# Заполняем пропуски\n",
        "df = df.fillna(df.median(numeric_only=True))\n",
        "\n",
        "# One-hot encoding для категориальных признаков\n",
        "df = pd.get_dummies(\n",
        "    df,\n",
        "    columns=['Company_Name', 'Job_Role', 'Experience_Level', 'City'],\n",
        "    drop_first=False\n",
        ")\n",
        "\n",
        "# Разделяем на признаки и целевую переменную\n",
        "X = df.drop('Salary_INR', axis=1)\n",
        "y = df['Salary_INR']\n",
        "\n",
        "# Train / Test разделение\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Масштабирование признаков\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Преобразуем в numpy массивы\n",
        "X_train_scaled = np.array(X_train_scaled)\n",
        "X_test_scaled = np.array(X_test_scaled)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Обучаем\n",
        "# Увеличиваем количество итераций для лучшей сходимости\n",
        "linreg_custom_best = LinearRegressionCustom(lr=0.01, n_iter=2000)\n",
        "linreg_custom_best.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Линейная регрессия (улучшенный бейзлайн) обучена\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COvUKQfG67tV",
        "outputId": "39250fa1-b74f-476b-881f-d764155ffafa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение завершено\n",
            "Форма вектора весов: (66,)\n",
            "Линейная регрессия (улучшенный бейзлайн) обучена\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**h. Оценка качества моделей с улучшенным бейзлайном**"
      ],
      "metadata": {
        "id": "LjIta6eO7RL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Предсказания\n",
        "y_pred_best_custom = linreg_custom_best.predict(X_test_scaled)\n",
        "\n",
        "# Метрики\n",
        "mae = mean_absolute_error(y_test, y_pred_best_custom)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_best_custom))\n",
        "r2 = r2_score(y_test, y_pred_best_custom)\n",
        "mape = np.mean(np.abs((y_test - y_pred_best_custom) / y_test)) * 100\n",
        "\n",
        "print(\"Имплементированная линейная регрессия (улучшенный бейзлайн)\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puRzxOWT7WSz",
        "outputId": "aa17354e-573f-47c7-b0b9-9c41c9048c48"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Имплементированная линейная регрессия (улучшенный бейзлайн)\n",
            "MAE: 391436.04\n",
            "RMSE: 489428.13\n",
            "R²: 0.5437\n",
            "MAPE: 39.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**i. Сравнить результаты моделей в сравнении с результатами из пункта 3**\n",
        "\n",
        "Сравнил метрики своей реализации LinearRegressionCustom на улучшенном бейзлайне с тем, что выдавал sklearn в пункте 3. Цифры получились абсолютно такие же: MAE около 391 тысячи, R² тот же самый 0.5437, да и MAPE совпал (39.19%).​\n",
        "\n",
        "Получается, что моя модель обучилась так же хорошо, как и библиотечная. Разницы в предсказаниях нет вообще, значит, алгоритм работает корректно и сходится к тому же оптимальному решению, что и в sklearn."
      ],
      "metadata": {
        "id": "xv2uYzpt73ep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**j. Выводы**\n",
        "\n",
        "\n",
        "Собственная линейная регрессия полностью справилась с задачей. На улучшенных данных (без выбросов и с One-hot encoding) она показала ровно такое же качество, как и готовая модель из библиотеки.​"
      ],
      "metadata": {
        "id": "m42oa6VP8GLs"
      }
    }
  ]
}